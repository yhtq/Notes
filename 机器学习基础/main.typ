#import "../template.typ": *
#show: note.with(
  title: "机器学习基础",
  author: "YHTQ",
  date: datetime.today().display(),
  logo: none,
  withChapterNewPage: true
)
#let ge(h) = $R(#h)$
#let ee(h) = $hat(R)(#h)$
#let er(h) = $hat(e)_r (#h)$
#let acc(h) = $hat(a) (#h)$
= 前言  
  - 教材：周志华《机器学习》
  - 期末考试：6.10 下午，闭卷笔试
  - 作业包括纸面作业和上机作业，都在教学网进行
  - 作业/考勤 40% + 期中 20% + 期末 40%
  - 教学大纲：
    + 机器学习概论
    + 计算学习理论
    + 机器学习基本模型和算法
    + 深度学习初步
= 基本概念
  == 监督学习
    所谓监督学习，就是基于一组数据 $T = {(x_i, y_i)}$ 来学习输入空间 $X$ 到输出空间 $Y$ 的映射。通常认为样本是独立同分布的。$y_i = c(x_i)$ 有时（$c$）也称为目标概念。所有概念记为 $C$，而所有可能的概念一般记为假设空间 $H$，往往与 $C$ 不同。学习算法基于 $T$ 得到一个假设 $h_T in H$
    #definition[损失函数][
      用 $L(h(x), y)$ 度量以 $h(x)$ 作为预测的预测好坏，常见的包括：
      - 0-1 损失
        $
          L(h(x), y) = delta_(h(x), y)
        $ 
      - 平方损失
        $
          L(h(x), y) = (h(x) - y)^2
        $
    ]
    #definition[泛化误差][
      给定损失函数，则：
      $
        ge(h) = E_(x tilde D) L(h(x), c(x))
      $
      表明平均意义下预测的好坏，称其为泛化误差
    ]
    注意通常来说，$x$ 的分布 $D$ 和真实概念 $c$ 都是未知的，因此泛化误差通常是无法实际计算的。
    #definition[经验误差/测试误差][
      - 给定训练数据集 $T$，则：
        $
          ee(H) = E_T L(h(x), y_i) = 1/N sum_i L(h(x_i), y_i)
        $
        称为经验误差（经验风险）。经验误差小未必保证泛化误差小，可能产生*过拟合*现象。

        更进一步，不同的机器学习理论可能给出对：
        $
          P(abs(approxVar(R)(h_T) - R(h_T)) < epsilon) 
        $
        的估计
      - 类似的，在测试集上计算的误差称为测试误差。通常来说，测试集的产生与训练过程无关，可以认为它们独立，同时有：
        $
          E_("test") (approxVar(R)_"test" (h_T)) = R(h_T) 
        $

    ]
    #definition[误差率/准确率][
      用：
      $
        er(h_T) = E_T delta_(h(x), y_i)
      $
      表示算法在 $T$ 上的误差率。用：
      $
        acc(h_T) = 1 - er(h_T)
      $
      表示算法在 $T$ 上的准确率。
    ]
    经验误差小并不能保证泛化误差足够小。
    
    实际二分类问题中，往往会将结果分为真/T 以及假/F，因此产生四类情况：
    - TP：真正例
    - FP：假正例
    - TN：真负例
    - FN：假负例
    通常：
    - $"TP"/("TF" + "TP")$ 称为准确率/查准率
    - $"TP"/("TP" + "FN")$ 称为召回率/查全率
    一般来说，查准率和查全率是相互抵触的。


    实际训练模型中，通常来说有两种策略：
    - 经验风险最小化：最小化经验误差
    - 结构风险最小化/正则化策略：
      $
        argmin_h approxVar(R) (h) + lambda J(h)
      $
      其中 $J(h)$ 为正则化项，$lambda$ 为正则化参数。实践上，这两者的选择方法是十分复杂的。
    
    由于超参数（例如 $lambda$ ）的存在，数据往往还要分出一部分用以验证，具体来说：
    - 选取不同的超参数，在训练集上训练
    - 在验证集上验证，选取最优的超参数
    - 在测试集上测试，得到最终的对模型的评价
    #algorithm[数据集的划分][
      通过验证数据选择超参数的过程称为模型选择，基本方法有：
      - 留出法/简单交叉验证法：通过无放回的随机采样，将数据划分为训练集和验证集。有时可以采用分层采样的方式，保证数据的分布。
      - $k$ 值交叉验证法：将数据划分为 $k$ 个大小相等的子集，每次取一个子集作为验证集，其余的作为训练集，重复 $k$ 次，得到 $k$ 个模型，取平均值作为该数据集下的结果。有时，也会重复多次以增强训练的稳定性。
      - 留一法：$k = N$ 的特殊情况，每次只取一个样本作为验证集，其余的作为训练集。这种方法训练数据比较大，但计算量也很大。
      - 自助法：通过有放回的采样，得到一定大小（通常为原数据集大小）的训练集，未被抽中的元素的作为验证集。这样采样可以保证最终训练模型时数据集大小与模型选择过程中相同，但得到的分布往往和原分布有所不同。
      这些流程结束后，可以选择最优的超参数在原数据集上重新训练模型，得到最终的模型。
    ]

    #definition[][
      - 定义：
        $
          overline(h) (x) = E_T h_T (x)\
          "Bias" (x) = E_T (h_T (x) - c(x)) \
          "Var" (x) = E_T (h_T (x) - overline(h) (x))^2
        $
        其中 Bias 是指该模型预测结果与实际结果的偏差，Vars 是指该模型使用不同数据集训练时的输出方差。
    ]
    #lemma[][
      $
        E_T (h_T (x) - c(x))^2 = "Bias" (x)^2 + "Var" (x)
      $
    ]
    表明泛化误差可以分解为方差和偏差的平方和。然而，实际上偏差小（表示对数据敏感）和方差小（对数据不敏感）往往是矛盾的。模型简单时，方差较小，但拟合能力弱，偏差较大；模型复杂时，偏差小，但模型更加敏感，方差较大。

    如果数据本身就有噪声，也即：
    $
      y = c(x) + epsilon
    $
    则有：
    $
      E_(T, epsilon) (h_T (x) - y)^2 = "Bias" (x)^2 + "Var" (x) + E_(T, epsilon) (epsilon)^2
    $
= 支持向量机
  以二分类任务为例，使用最简单的线性模型，就是找一个超平面将数据分开：
  - 若假设存在这样一个超平面，如何找到？
  - 若不假设，如何找到一个最优的超平面？
  == 线性可分支持向量机
    称一个数据集 $T = {(x_i, y_i)}$，其中 $y_i in {1, -1}$ 是线性可分的，如果存在一个超平面 $w^T x + b = 0$，使得对所有的 $i$ 有 $y_i (w^T x_i + b) > 0$，该超平面称为分离超平面。

    若模型正确分类，则一定有：
    $
      y_i (w^T x_i + b) > 0, forall i
    $
    为了找到最好的超平面：
    - 由齐次性，不妨假设：
      $
        abs(w x_i + b) >= 1
      $
    - 特别的，对于 $y_i (w x_i + b) = 1$ 的样本点而言，它们就是距离超平面最近的点，而这样的点到分离平面的距离恰好为 $1/norm(w)$
    - 我们把 $2/norm(w)$ 称为*间隔*，也就是一对离超平面最近的点的距离。目标即是找到间隔最大的超平面
    因此，我们得到了优化问题：
    $
      max_(w, b) 1/(norm(w)) suchThat y_i (w^T x_i + b) >= 1, forall i 
    $
    其中 $1/(norm(w))$ 为间隔，表示超平面到最近的点的距离。它可以转化为凸优化问题：
    $
      min_(w, b) 1/2 norm(w)^2 suchThat y_i (w^T x_i + b) >= 1, forall i
    $
    这是凸二次优化问题，只要有解（原问题线性可分），则解唯一。称它的解为最大间隔分离超平面。对应的分类决策函数就是下面的“神经元”：
    $
      f(x) = sgn(w^T x + b)
    $
    为了求解这个问题，构造拉格朗日函数：
    $
      L = 1/2 norm(w)^2 - sum_(i = 1)^N alpha_i - sum_(i = 1)^N alpha_i y_i (w^T x_i + b)
    $
    求导可得：
    $
      w = sum_i alpha_i y_i x_i\
      sum_i alpha_i y_i = 0
    $
    对于非平凡的数据集，一定有 $w != 0$，因此 $alpha_i$ 不能全为零。将以上两式代回，可以证明：
    $
      L = sum_i alpha_i - 1/2 sum_(i, j) alpha_i alpha_j y_i y_j x_i^T x_j
    $
    因此原问题等价于：
    $
      max_alpha sum_i alpha_i - 1/2 sum_(i, j) alpha_i alpha_j y_i y_j x_i^T x_j \
      suchThat sum_i alpha_i y_i = 0, alpha_i >= 0
    $
    这个问题被称为原问题的对偶问题。

    由 KKT 条件，若 $alpha_i != 0$，则：
    $
      y_j (w^T x_j + b) = 1\
      b = y_j - w^T x_j = y_j - sum_(i = 1)^N alpha_i y_i x_i^T x_j
    $
    由上面的推导，往往也将支持向量机写作：
    $
      sgn(sum_i alpha_i y_i x_i^T x + b)
    $
    事实上，由 KKT 条件还有：
    $
      alpha_i (y_i (w^T x_i + b) - 1) = 0
    $
    还可以得到：
    $
      norm(w)^2 &= inner(w, sum_i alpha_i y_i x_i)\
      &= sum_i alpha_i y_i inner(w, x_i)\
      &= sum_i alpha_i y_i (y_i - b)\
      &= sum_i alpha_i y_i^2 - b sum_i alpha_i y_i\
      &= sum_i alpha_i \
    $
    因此可得间隔的表达式：
    $
      2/norm(w) = 2/(sqrt(sum_i alpha_i))\
    $
    因此，事实上我们希望不为零的 $alpha_i$ 尽可能少，这些向量就被称为支持向量。显然支持向量就是恰好成立：
    $
      abs(w^T x_i + b) = 1
    $
    的那些向量。


    可以证明，假设在训练集 $D$ 上采用留一法，定义留一误差为：
    $
      ee(f) = 1/N sumBrN1(I(f_(D^(-i)) != y_i))
    $
    则有：
    $
      ee(f) <= 1/N N_("SV")(f)
    $
    其中 $N_("SV")(f)$ 是支持向量的个数。（该估计仅做了解）
  == 非线性可分支持向量机
    在大多数时候，要求线性可分有些严苛。此时，不仅要最小间隔尽可能大，还要希望分类错误的点尽可能少。因此，我们为每个点引入松弛量 $xi_i$，约束条件变为：
    $
      y_i (w x_i + b) + xi_i >= 1
    $
    我们将 $xi_i != 0$ 的点称为特异点。如果只考虑非特异点，则情形是与线性可分情形相同的。为了区分起见，我们将此时的间隔称作软间隔，可分情形称作硬间隔。我们希望间隔尽可能小，并且特异点也要尽可能少，因此我们得到了优化问题：
    $
      min_(w, b) 1/2 norm(w)^2 + C sum_i 1_(xi_i !=0) \ 
      suchThat y_i (w x_i + b) >= 1 - xi_i, xi_i >= 0
    $
    实践上，往往采用以下的松弛版本：
    $
      min_(w, b) 1/2 norm(w)^2 + C sum_i xi_i\
      suchThat y_i (w x_i + b) >= 1 - xi_i, xi_i >= 0
    $<sv-2>
    有时也可采用 $C sum_i xi_i^p$ 作为松弛项。

    在上面的问题中，显然取 $xi_i = max(0, 1 - y_i (inner(w, x_i) + b))$ 即可。因此引入合页损失函数：
    $
      h(z) = max(0, 1 - z)
    $ 
    问题等价为
    $
      min_(w, b) 1/2 norm(w)^2 + C sum_i h(y_i (inner(w, x_i) + b))
    $
    或者：
    $
      min_(w, b) 1/2 sum_i max(0, 1 - y_i (inner(w, x_i) + b)) + 1/C norm(w)^2
    $
    事实上，这就是采取合页损失的结构风险最小化策略。事实上，之前的松弛就是用合页损失替代了 $0-1$ 损失。当然也可以采用二次损失替代合页损失。

    回到@sv-2，假如使用拉格朗日乘子法，可以得到拉格朗日函数：
    $
      L = 1/2 norm(w)^2 + C sum_i xi_i - sum_i alpha_i (y_i (inner(w, x_i) + b) - 1 + xi_i) - sum_i beta_i xi_i
    $
    求导得到：
    $
      w = sum_i alpha_i y_i x_i\
      sum_i alpha_i y_i = 0\
      alpha_i = C - beta_i
    $
    化简得到：
    $
      L = sum_i alpha_i - 1/2 sum_(i, j) alpha_i alpha_j y_i y_j inner(x_i, x_j)
    $
    因此得到对偶问题：
    $
      max_alpha sum_i alpha_i - 1/2 sum_(i, j) alpha_i alpha_j y_i y_j inner(x_i, x_j)\
      suchThat sum_i alpha_i y_i = 0, 0 <= alpha_i <= C
    $<sv-3>
    可以看到，形式上只是增加了约束 $alpha_i <= C$，同时许多结论仍然成立：
    - 仍然可以将 $alpha_j > 0$ 的点称为支持向量
    - $w = sum_i alpha_i y_i x_i$
    - $b = y_i - sum_j alpha_j y_j inner(x_j, x_i)$
    - 在所有的支持向量中，$0 < alpha_i < C$ 的点落在分类边界上，$alpha_i = C$ 的点是特异点。
    可以证明，最优平面的法向量 $w$ 是唯一的，但偏置 $b$ 往往不唯一，需要后续实验确认，或者多次求值后取平均
  == SMO 算法
    Platt 提出的*序列最小最优化算法（SMO）*可以高效地解决@sv-3 这种二次规划问题。其基本思想是：
    - 将多个拉格朗日乘子的问题化减到仅有两个乘子的问题。往往，我们选择第一各变量是违反 KKT 条件最严重的，第二个变量是使得目标函数增加最快的。
    - 仅有两个乘子的二次规划问题有解析解
    首先考虑仅有两个乘子的问题求解：
    #algorithm[][
      假设当前只更新拉格朗日乘子 $alpha_1, alpha_2$，约束：
      $
        sum_i alpha_i y_i = 0
      $
      给出：
      $
        alpha_1 y_1 + alpha_2 y_2 = - sum_(i != 1, 2) alpha_i y_i\
        alpha_1 + alpha_2 y_1 y_2 = - y_1 sum_(i != 1, 2) alpha_i y_i
      $
      令 $s = y_1 y_2, gamma = - y_1 sum_(i != 1, 2) alpha_i y_i$，则原问题转化为
      $
        max_(alpha_1, alpha_2) W(alpha_1, alpha_2)\
        suchThat 0 <= alpha_1, alpha_2 <= C, alpha_1 + s alpha_2 = gamma
      $
      事实上，使用 $alpha_1 = gamma - s alpha_2$ 代换后，这就是关于 $alpha_2$ 的一元二次函数，可以直接求最大值。

      注意每次更新 $alpha_1, alpha_2$ 后，都需要更新 $b$. 若 $alpha_1, alpha_2$ 中至少一个非零，则应该采用 $b = y_j - inner(sum_i alpha_i y_i x_i, x_j)$ 更新
    ]
    - 选择需要更新的变量：往往选择违反 KKT 条件最严重的变量，第二个变量选择一个使得目标函数增加最快的变量
  == 核方法 
    许多问题是完全不能依靠线性函数划分的。一个很自然的想法是构造映射 $phi$，使得 $phi(X)$ 线性可分。得到最优化问题：
    $
      min_(w, b, xi) 1/2 norm(w)^2 + C sum_i xi_i\
      suchThat y_i (inner(w, phi(x_i)) + b) >= 1 - xi_i, xi_i >= 0
    $
    或者对偶问题：
    $
      max_alpha sum_i alpha_i - 1/2 sum_(i, j) alpha_i alpha_j y_i y_j inner(phi(x_i), phi(x_j))\
      suchThat sum_i alpha_i y_i = 0, 0 <= alpha_i <= C
    $
    实际应用上，$phi$ 是难以构造的。经典的处理方式是引入*核函数*：观察上面的对偶问题，事实上我们不关系 $phi$ 的具体值，只关心：
    $
      K(x_1, x_2) = inner(phi(x_1), phi(x_2))
    $
    在数据集上的值，因此合理选择核函数即可，最终的分类函数形如：
    $
      f(x) = sgn(sum_i alpha_i y_i K(x_i, x) + b)\
      b = y_j - sum_i alpha_i y_i K(x_i, x_j)
    $
    往往我们会选择正定对称的核函数，常用的包括：
    - 线性核函数：$K(x, z) = inner(x, z)$
    - 多项式核函数：$K(x, z) = (inner(x, z) + 1)^p$
    - 高斯核函数：$K(x, z) = exp(-d(x, z)^2 / (2 sigma^2))$
= 基于后验概率最大化准则的分类模型
  之前我们的思路是学习得到一个预测函数。我们也可以采取其他思路：给定数据集 $T$，我们希望学习得到一个概率分布 $P(y | x)$，并通过该分布下后验概率最大的 $y$ 作为预测值。
  == 分类准则
    设 $y$ 的可能值为 $autoRListN(c, n)$，如果给定一个损失函数 $l(y, y')$，定义将 $x$ 预测为 $c_i$ 的风险（期望损失）为：
    $
      R(y = c_i | x) = sum_(j = 1)^n l(c_i, c_j) P(y = c_j | x)
    $
    最优（风险最小）的预测为：
    $
      hat(y) = argmin_(c_i) R(y = c_i | x)
    $
    如果采取 0-1 损失，不难验证：
    $
      R(y = c_i | x) = 1 - P(y = c_i | x)
    $
    显然，此时损失最小等价于 $argmax_(c_i) P(y = c_i | x)$，也就是后验概率最大准则。

    通常而言，贝叶斯模型分为判别式模型和生成式模型：
    - 判别式模型：直接建模 $P(y | x)$，例如逻辑回归
    - 生成式模型：建模 $P(x | y)$，然后通过贝叶斯公式计算 $P(y | x)$
  == 逻辑斯谛回归
    #definition[二阶逻辑斯谛回归][
      设 $x$ 为 $n$ 维向量，$y$ 为二分类变量，$P(y = 1 | x) = p(x)$，则称以下分布：
      $
        P(y = c_1 | x) = e^(w^T x + b) / (1 + e^(w^T x + b))\
        P(y = c_2 | x) = 1 / (1 + e^(w^T x + b))
      $
      是二阶逻辑斯谛回归模型，其中 $w$ 是参数，$b$ 是偏置。事实上，这相当于二元形式的 softmax 函数。
    ]
    事实上，对于给定的 $x$，将其分到 $c_1$ 还是 $c_2$ 取决于 $w x + b$ 的正负，因此最终判断的准则是线性的（由于是取对数后得到线性函数，因此也称为*对数线性模型*）

    给定数据集，最常见的参数估计方法就是最大似然估计，也就是希望：
    $
      argmax_(w, b) = L(w, b) = prodi1N(P(y_i | x_i))
    $
    可以计算得：
    $
      ln L(theta) = sumi1N(y_i (w^T x_i + b) - ln(1 + e^(w^T x_i + b)))
    $
    该方程没有解析解，但根据偏导为零，可以求得：
    $
      sumi1N(x_i (y_i - p(y_i = 1 | x_i, w, b))) = 0\
      sumi1N(y_i - p(y_i = 1 | x_i, w, b)) = 0
    $
  == 朴素贝叶斯模型
    贝叶斯公式给出：
    $
      P(y = c_i | x) = (P(x | y = c_i) P(y = c_i)) / sumk1M(P(x | y = c_k) P(y = c_k))
    $
    而分母实际上不影响我们分类，因此我们的任务是：
    - 从数据集得到 $Y$ 和 $X | Y$
    - 从贝叶斯公式计算得到 $Y | X$
    假定 $X$ 是离散的，可能取值为 $N$，则理论上，只需要估计 $N M$ 个参数，但是这个量往往过大。所谓朴素贝叶斯，就是认为 $X$ 分成多个相互独立的特征 $X_1, X_2, ..., X_n$，因此：
    $
      P(X = x | y) = prodi1n(P(X_i = x_i | y))
    $
    假设第 $i$ 个特征有 $m_i$ 个取值，独立性假定将参数量从 $M(prodi1n(m_i))$ 降低到了 $M(sumi1n(m_i))$，显然有大幅度的下降。类似的，我们还是使用极大似然估计，事实上由于是离散值，因此就是直接使用频率估计：
    $
      P(y = c_k) = sum_(y = c_k) 1/N\
      P(X_i = x_(i j) | y = c_k) = (sum_(X_i = x_(i j), y = c_k) 1)/(sum_(y = c_k) 1)
    $
    由此计算后验概率，注意到后验概率与 $P(x | y = c_i) P(y = c_i)$ 成正比，因此类别预测准则为：
    $
      y = argmax_(c_i) P(y = c_i) prodi1n(P(X_i = x_i | y = c_i))
    $
    注意在这样的估计中，可能将某个参数估计为零，导致多个概率相乘仍是零。因此有改进方法：
    - 使用：
      $
        ((sum_(X_i = x_(i j), y = c_k) 1) + lambda)/((sum_(y = c_k) 1) + lambda m_j)
      $
      矫正 $P(X | Y)$
    - 使用：
      $
        ((sum_(y = c_k) 1) + lambda)/(N + lambda M)
      $
      矫正 $P(Y)$
    简单来说，就是对每个频数加一个 $lambda$ 扰动。$lambda = 1$ 时称为 Laplace 平滑，实际上这与所谓的*贝叶斯估计*的结果是一致的。
= 基于近邻的分类方法
  这类方法又称为免模型方法或者惰性学习，最终得到的不是一个显式的模型，而是根据新样本落在哪一类作为预测结果。这类方法的核心问题包括：
  - 如何度量数据的相似性
  - 选择哪些与新数据相似的实例
  - 如何利用选定样本的类标记来预测新数据的类标记
  在特征空间为 $RR^n$ 的情况下，最常用的距离度量是 MinKowski 距离。给定度量，我们有经典的 k-近邻法：
  - 基于度量，对于任意 $x$ 找出训练集中与 $x$ 最近的 $k$ 个点，这些点构成邻域 $N_k^(dist)$，其中的类标签采用简单投票多数占优原则。
  - 经验风险为：
    $
      1/k sum_(x_i in N_k^dist) I(y_i != y)
    $
    其中 $y$ 是选择的类标签。
  一般来说，$k$ 值小时模型方差大，$k$ 值大时模型偏差大，实践上往往从较小的 $k$ 开始，逐渐增大，直到模型的性能不再提升为止。

  当 $k = 1$ 时，该方法称为最近邻法。某种意义上，最近邻法相当于将空间按照最靠近的点做了划分，每个划分单元赋予一个类标签。
  == K-Means 方法
    一个自然的想法是，能否将数据集中靠近的样本合并，再用一个点替代。K-Means 方法就是找到 $k$ 个这样的点：
    - 选择任意 $k$ 个初始点
    - 将每个点划分到离它最近的点，构成 $k$ 元的划分
    - 对每个划分，计算其中心，用该中心替代原来的初始点
    - 重复进行直至收敛
    完成聚类后，再将得到的 $k$ 个类作为最近邻法的数据集进行分类。$k-$ 近邻法的缺陷是，代表点离分类边界很近时，很容易分类错误。
  == 学习向量量化方法
    学习向量量化方法是对 K-Means 方法的改进，设样本空间为 $X$，则它使用 $X^k$ 而非 $X$ 作为类中心点的标记：
    - 初始时，在每个类 $c_m$ 中选择 $k$ 个点构成该类的代表向量：
      $
        autoRVecN(I^m, k)
      $
    - 随机选取一个样本，找到最近的代表点 $I^i_j$
      - 若该样本的类别是 $i$，则更新：
        $
          I^i_j = I^i_j + eta (x - I^i_j)
        $
      - 否则，更新：
        $
          I^i_j = I^i_j - eta (x - I^i_j)
        $
      其中 $eta in (0, 1)$ 是预先确定的学习率
    - 重复进行，直到收敛
    可以注意到，在更新过程中，如果同类别，就有：
    $
      norm(x - (I^i_j + eta (x - I^i_j))) = (1 - eta) norm(x - I^i_j) <= norm(x - I^i_j)
    $
    如果不同类别，就有：
    $
      norm(x - (I^i_j - eta (x - I^i_j))) = (1 + eta) norm(x - I^i_j) >= norm(x - I^i_j)
    $
= 决策树方法
  对于分类问题，我们也可以采用决策树方法，根据规则对数据进行分类。大致算法是将数据根据某个特征分成树，直到无特征可用时，用剩余数据的最多的样本值作为该分支的样本值。
  == 基本决策树
  #definition[经验熵][
    定义训练集的经验熵如下：
    $
      H(D) = - sumBrN1(p_i log_2 p_i) where p_i = abs(D_i)/abs(D)
    $
    它度量了数据集的“纯度”，经验熵越大，数据集的信息量越大。可以证明在 $p_i$ 都相等的时候，经验熵最大。
  ]
  #definition[][
    对于特征 $A$，其对数据集 $D$ 的经验条件熵定义为：
    $
      H(D|A) = sumk1m(abs(D_k^A)/abs(D) H(D^A_k))
    $
    其中 $D_k^A$ 是 $D$ 中所有特征 $A$ 取 $k$ 的数据。
    进一步，定义信息增益为：
    $
      G(D, A) = H(D) - H(D|A)
    $
  ]
  直观来说，我们应该向着信息增益越大的方向分类。然而，信息增益有一个缺点，它偏向于选择取值较多的特征。因此，我们可以引入校正项：
  #definition[][
    定义信息增益比：
    $
      G(D, A) =( H(D) - H(D|A)) / H(A)
    $
    其中 $H(A)$ 是特征 $A$ 的熵（也称分裂信息/固有值） $- sumk1m(abs(D^A_k)/abs(D) log_2 abs(D^A_k)/abs(D))$。信息增益比越大，表明特征 $A$ 的分类能力越强。
  ]
  注意增益比会偏好取值少的特征，因此实践上往往选取增益比高于某个阈值的，信息增益最大的特征。

  除了使用熵作为指标，还可以选择其他的指标：
  #definition[][
    定义基尼指数：
    $
      "Gini"(D) = 1 - sumBrN1(p_i^2)
    $
    它相当于从数据集中随机抽取两个样本，类别不一致的概率。基尼指数越小，数据集的纯度越高。

    类似的，定义特征 $A$ 对数据集 $D$ 的基尼指数：
    $
      "Gini"(D, A) = sumk1m(abs(D_k^A)/abs(D) "Gini"(D^A_k))
    $
    它越小，表明特征 $A$ 的分类能力越强。
  ]
  选定一个指标 $F$，我们就可以设计一般的决策树算法：
  + 若样本集 $D$ 中所有元素属于同一类别 $C$，则返回单节点树 $T$
  + 若 $A = emptyset$，且 $D$ 非空，则生成以 $D$ 中样本数最多的类别 $C$ 为标记的节点
  + 否则，计算所有特征 $A$ 对数据集 $D$ 的度量，选择最优特征 $A_*$，划分数据集 $D$ 为 $D_1, D_2, ..., D_n$，对于每个 $D_i$ 递归生成决策树
  历史上，选择信息增益最大的算法称为 ID3 算法，选择信息增益比最大的算法称为 C4.5 算法，选择基尼指数最小的算法称为 CART 算法。注意 ID3, C4.5 算法中，我们对 $A$ 的每个取值做多路划分，而 CART 只对 $A = a_i, A eq.not a_i$ 做二路划分，选择特征时也要选择最优的划分点。显然多路划分得到的决策树更小，但实践表明其泛化能力和二路划分差别不大。

  然而，决策树也可能产生“过拟合”，因此我们希望对决策树进行剪枝，以达到某种结构风险最小。大致分为两种策略：
  - 预剪枝策略：在生成过程中，基于验证集对当前划分做出评估，如果泛化能力未提升则直接标记为叶节点。然而，这种方法相当于提前禁止一些分支展开，可能会导致欠拟合。
  - 后剪枝策略：生成完成后，对决策树进行剪枝，根据验证集比较剪枝后的树和原树的泛化能力，选择最优的树。这种方法相对来说更加保守，但是也更加稳定。
  同时，后剪枝策略也可以采取正则化方法。给定一个决策树 $T$，可以将损失函数定为：
  $
    C_alpha(T) = C(T) + alpha abs(T)
  $
  其中 $C(T)$ 是拟合程度，例如：
  $
    C(T) = sum_(t = 1)^abs(T) N_t H_t (T)
  $
  其中 $N_t$ 是叶节点 $t$ 的样本数，$H_t (T)$ 是叶节点 $t$ 的经验熵（事实上 $C(T)$ 接近于负的对数似然函数）。$alpha$ 是正则化参数，用以平衡拟合程度和模型复杂度。

  CART 算法有特别的剪枝处理方式，会产生一个递增的权衡系数序列和对应的最优子树（依次嵌套），将会使用交叉验证法来选择其中最优的一个。

  有时，我们也会遇到特征连续的数据。此时，常用策略是对于每个特征，列出出现在数据集中的所有情况，取所有中点作为划分点。

  另外，有时会出现有数据的某些特征缺失的情况。典型的处理方法是：
  - 使用对样本加权的方式计算占比和熵
  - 选择特征时，用 $"该特征未缺失数据占比" times "在该数据未缺失数据构成的数据集上的信息增益"$ 作为信息增益
  - 划分数据时，若该特征缺失，则将数据等权重的划分到所有子节点中
  == 最小二乘回归树
    有时，我们也可以使用决策树进行回归。对于回归问题，我们可以使用最小二乘回归树。其基本思想是将输出函数变成阶梯形：
    $
      f(x) = sum_(m = 1)^M c_m 1_(x in R_m)
    $
    其中 $R_m$ 是选定的单元，通常 $c_m$ 就是 $R_m$ 中所有数据的均值（这样可以达到最小的最小二乘误差）。只要选定 $R_m$，问题就变成了分类问题。具体操作如下：
    - 选择一个特征 $j$ 和一个切分点 $s$，将数据集划分为 $R_1(j, s) = {x|x_j <= s}$ 和 $R_2(j, s) = {x|x_j > s}$，使得：
      $
        min_(c_1) sum_(x_i in R_1) (y_i - c_1)^2 + min_(c_2) sum_(x_i in R_2) (y_i - c_2)^2
      $
      最小。（显然上式中 $c_1, c_2$ 的最优值就是 $R_1, R_2$ 中所有数据的均值）
    - 基于上面的 $j, s$，将数据集划分为 $R_1, R_2$，重复上述过程，直到达到停止条件。
    类似的，我们也可以仿照前面的思想进行剪枝。采用损失函数：
    $
      C_alpha (T) = C(T) + alpha abs(T)
    $
    其中：
    $
      C(T) = sum_(t = 1)^abs(T) N_i Q_i (T)\
      where Q_t (T) = 1/N_t sum_(x_i in R_t) (y_i - c_t)^2
    $
  == 小结
    - 决策树模型是基于特征对实例进行分类的树形结构。
    - 学习算法往往采用贪心策略
    - ID3 算法，C4.5 算法，CART 算法是常见的决策树学习算法，分别采用信息增益最大，信息增益比最大，基尼指数最小作为特征选择准则。
    - ID3 算法，C4.5 算法采用多路划分，CART 算法采用二路划分。
    信息熵、条件信息熵的计算需要掌握
= 神经网络学习初步
  == M-P 神经元模型，多层前馈神经网络
    前面的许多机器学习模型可以表达为线性模型和非线性模型的组合。也就是，先计算一个线性结果，再使用非线性的激活函数处理线性结果，这就是一个 M-P 神经元。
    #definition[Sigmoid][
      定义：
      $
        f(x) = 1/(1 + exp(-x))
      $
      为 Sigmoid 函数，它是一个很传统的激活函数。
    ]
    #definition[多层前馈神经网络][
      称：
      - 神经元逐层排列，相邻层神经元全连接，不相邻层无连接
      - 第一层为输入层，最后一层为输出层，中间层为隐藏层
      - 除输入层外，每层都通过激活函数处理输入
    ]
    通常而言，宽度和深度都能增加神经网络的表达能力，但深度往往更加经济。
    
    前面讨论的支持向量机模型可以看作是无隐藏层，采用符号函数作为激活函数的神经网络。对于单隐层前馈神经网络，可以写出模型的表达式：
    $
      Y = sigma(V sigma(W X + gamma) + theta)
    $
    可以计算得，单隐藏层前馈网络的参数集为：
    $
      (Union_(t = 1)^m {w_(j t)}_(j = 1)^n) union Union_(l=1)^k {v_(t l)}_(t = 1)^m union {theta_l}_(l=1)^k union {gamma_t}_(t = 1)^m
    $
    其中 $gamma, theta$ 分别是隐藏层，输出层的偏置。总计 $(n + k + 1) m + k$ 个参数。

    对于损失函数，经典的经验风险最小化策略是，用平方误差度量输出层在数据集上的损失，也就是：
    $
      R(Theta) = norm2(Y - hY)
    $
    训练时，往往采用梯度下降策略，有：
    $
      der(R(Theta), hY) = 2 (hY - Y)^T \
    $
    如果使用 Sigmoid 函数作为激活函数，则：
    $
      der(sigma(y), y) = sigma(y) (1 - sigma(y))\
    $
    因此：
    $
      der(hY, V sigma(W X +gamma) + theta) = (sigma(V sigma(W X +gamma) + theta) (1 - sigma(V sigma(W X +gamma) + theta))) dot *\
    $ 
    通常记 $delta = 2(hY - Y) dot (sigma(V sigma(W X +gamma) + theta) (1 - sigma(V sigma(W X +gamma) + theta)))$，被称为误差项。

    给定学习率 $eta$，标准的梯度下降算法如下：
    $
      x = x - eta der(R(x), x)\
    $
    同时，通常选择参数时，不会选择零值而是靠近零的随机值作为参数初始值，避免所有信号全为零。从根本上，这是因为 Sigmoid 函数具有某种饱和性，因此现代神经网络往往不再使用 Sigmoid 函数，而是使用其他激活函数。
    #example[常用激活函数][
      - 整流线性函数 RELU:
        $
          f(x) = max(0, x)
        $
      - 带泄漏的整流线性函数 Leaky RELU:
        $
          f(x) = max(0, x) + alpha min(0, x)
        $
    ]

    实际训练时，往往采用*批量*随机下降法，也就是将数据分成不同的部分，每次使用一个批量进行参数更新。
= 集成学习
  有时，单个的学习器未必效果较好。通过将相对比较容易构建但泛化能力一般的多个学习器进行结合，可能得到更好的泛化能力，这种思想称为*集成学习*
  
  根据集成学习中个体分类器是否由统一算法得到的，将集成学习分为同质的和异质的：
  - 对于同质的集成学习，每个学习器都由同一学习算法获得，相应的个体学习器称为基学习器，学习算法为基学习算法
  - 反之就是异质的，并称相应的个体学习器为组件学习器

  此外，根据个体学习器的组件之间关系，将集成学习分为序列化方法和并行化方法：
  - 有依赖性的个体学习器只能串行学习，例如提升方法
  - 无依赖关系的个体学习器可以并行学习，例如 Bagging 方法，随机森林
  == 提升方法
    #definition[弱学习算法][
      若某算法的平均误差好于随机猜测，则称该算法为弱学习算法
    ]
    #definition[强学习算法][
      若当样本数量充分大时，平均误差以大概率任意小，则称该算法为强学习算法
    ]
    理论上可以证明，在 PAC 框架下一个问题是强可学习的当且仅当是弱可学习的，但在实践中设计弱学习算法往往更容易一些，因此将弱学习算法提升得到强学习算法的方法称为提升方法。
    #algorithm[Adaboost][
      对于二分类问题，采用加权多数表决的方式对若干个依次学到的同质的弱分类器进行集成。这是一种序列化方法，投票权重由该学习器的性能决定。具体来说：
      - 给定数据集 $D, y in {-1, 1}$
      - 第 $t$ 轮时，用 $w_(i t)$ 作为第 $t$ 轮时数据 $i$ 的权重，用来保证得到的弱分类器不同
      - 通常取 $w_(i 1) = 1/N$，之后的权值由之前轮学习器得到的结果进行调整
      - 第 $t$ 轮时，按照：
        $
          f_t = argmin_f sumi1N(w_(i, t) I(f(x_i) != y_i))\
        $
        得到该轮的基分类器 $f_t$
      - 计算 $f_t$ 的分类错误率：
        $
          e_t = sum_(i=1)^N w_(i, t) I(f_t (x_i) != y_i)\
        $
        以此计算 $f_t$ 在加权投票中的权值：
        $
          alpha_t = 1/2 ln((1 - e_t)/e_t)\
        $
      - 同时，采用如下方法更新 $W$:
        $
          w_(i, t + 1)' = w_(i, t) e^(- alpha_t y_i f_t (x_i))\
          w_(i, t + 1) = w_(i, t + 1)'/sumj1N(w_(j, t + 1)')\
        $
      - 经过 $T$ 轮学习后，按照：
        $
          G(x) = sgn(sum_(t = 1)^T alpha_t f_t (x))
        $
        进行预测。
      注意在序列学习中，未必保证每一轮都比上一轮好，只是保证最后的结果比单个弱学习器好。

      此外，注意到：
      $
        Z_t &:= sumj1N(w_(j, t + 1)') = sumj1N(w_(j, t)) e^(- alpha_t y_j f_t (x_j))\
        &= sum_(y_i != f_t (x_i)) w_(i, t) e^(alpha_t) + sum_(y_i = f_t (x_i)) w_(i, t) e^(-alpha_t)\
        &= e_t e^(alpha_t) + e^(-alpha_t) (1 - e_t)\
      $
      可以证明上式恰为：
      $
        Z_t = 2 sqrt(e_t(1 - e_t))
      $
      
      理论上可以证明，只要 $e_t$ 都小于 $1/2$，得到的结果就是强学习算法。如果在实际使用时出现 $e_t >= 1/2$，需要额外处理。一种处理方法时到该步就放弃，另一种方法是重新采样数据重新开始。

      最终有：
      $
        hat(R)(f) &= 1/N sumi1N(I(y_i G(x_i)) <= 0)\
        &<= 1/N sumi1N(e^(-y_i G(x_i)))\
        &= product_(t = 1)^T Z_t\
        &= product_(t = 1)^T 2 sqrt(e_t (1 - e_t))\
        &= product_(t = 1)^T sqrt(1 - 4 (1/2 - e_t)^2)\
        &<= e^(-2 sum_(t = 1)^T (1/2 - e_t)^2)
      $
      假设存在 $gamma$ 使得 $1/2 - e_t >= gamma$，就有：
      $
        hat(R)(f) <= e^(-2 T gamma^2)
      $
      表明误差以负指数速度快速下降。
    ]

    #definition[加法模型][
      设 $f_i$ 是若干基分类器，则：
      $
        G(x) = sum_(t = 1)^T alpha_t f_t (x)
      $
      称为一个加法模型。
    ]
    显然，上面的 Adaboost 方法就是加法模型的一种。事实上，我们如果假设使用指数损失函数 $e^(-y f(x))$，则第 $t$ 步时，就是要求：
    $
      argmin_(alpha, f) 1/N sum_(i = 1)^N e^(-y_i (G_(t - 1) (x_i) + alpha f(x_i)))
    $
    可以计算得：
    $
      G_t (alpha, f) = product_(s = 1)^(t - 1) Z_s (sum_(i = 1)^N w_(i, t) e^(-y_i alpha f(x_i)))
    $
    记 $e_t = sum_(y_i != f(x_i)) w_(i, t)$，不难求得：
    $
      f_t = argmin_f e_t\
      alpha = 1/2 ln((1 - e_t)/e_t)
    $
    这就是 Adaboost 算法的结果。
    #algorithm[提升树模型][
      设 $T(x)$ 是基决策树，构造目标加法模型：
      $
        f(x) = sum_(m = 1)^M T(x)
      $
      构造方法为给定损失函数 $L$，则第 $m$ 个基学习器由以下经验风险最小化学得：
      $
        T_m = argmin_f 1/N sum_(i=1)^N L(y_i, f_(m - 1) (x_i) + f(x_i))
      $
      事实上，就是拟合目前剩余的残差。
    ]
  == Bagging 与随机森林
    对训练样本进行重采样，利用不同的样本数据来学习不同的基学习器，降低方差是一类典型的思路，Bagging 算法就是其中的代表。
    #algorithm[Bagging][
      Bagging 算法的流程如下：
      - 每次从 $N$ 个样本的训练数据集中利用自助法，得到 $N$ 个采样
      - 训练 $M$ 个基学习器，每个基学习器在不同的采样上进行训练
      - 对每个基学习器的预测结果进行投票或平均，得到最终的预测结果
      典型的，对于样本 $x_i$，称未使用 $x_i$ 进行训练的基学习器的预测结果作为*包外预测*
    ]
    #algorithm[随机森林][
      在 Bagging 算法的基础上引入随机属性选择，就得到了随机森林模型。所谓随机选择特征是指，决策树在选择划分特征时，先从当前结点的所有特征（不妨设为 $d$ 个特征）中选择 $k$ 个作为候选，再从 $k$ 个特征中选择最优划分。
      - 当 $k = d$ 时，则随机森林模型就是基学习算法采用决策树的 Bagging
      - 当 $k < d$ 时，相当于在特征选择时引入随机波动
      - 当 $k = 1$ 时，相当于随机选择一个特征
      参数 $k$ 在实践上一般推荐 $k = log_2 d$

      随机森林方法比单纯的 Bagging 方法增加了基学习器的多样性差异，然而每个基学习器训练时因为选择特征变少，理论性能可能降低。随着基学习器数目的增加，随机森林通常会收敛到比 Bagging 更低的泛化误差。
    ]
= 聚类算法  
  聚类是一种典型的无监督学习问题，目标是将数据集划分为若干个簇，使得同一簇内的样本相似度高，而不同簇之间的样本相似度低。
  == 高斯混合模型
  == EM 算法
    对于一类含有隐变量的模型，EM 算法是常见的求解策略。通常来说，目标是最大化：
    $
      L(theta) = ln sum_z P(y, z | theta)
    $
    使用迭代方法，假设 $theta^i$ 已经确定，可以证明：
    $
      L(theta) >= L(theta^i) + sum_z p(z | y, theta^i) ln(p(y, z | theta)/(p(z | y, theta^i) p(y | theta^i)))\
    $
    我们的策略是转化为令上式右侧最大，等价于让：
    $
      sum_z p(z | y, theta^i) ln(p(y, z | theta)) = E_z (ln p(y, z | theta) | y, theta^i)
    $
    最大。求解该优化问题就得到的 $theta^(i + 1)$

    EM 算法对于初始值是相当敏感的，因此往往会多次求解选择最优的结果。此外，EM 算法也不能保证收敛到最优点，但可以保证似然函数的值单调递增。
  == 层次聚类方法
    之前提到的模型都是一致的聚类方法，聚类个数不变。如果在聚类过程中动态的调整聚类个数，就称为层次聚类方法。层次聚类方法分为自底向上和自顶向下两种：
    - 将所有样本视作一个簇，逐步拆分成更小的簇的方法称为自顶向下的方法
    - 将每个样本视作一个簇，逐步合并成更大的簇的方法称为自底向上的方法
    通常来说，层次聚类方法不用事先设定聚类个数，而是设定一个停止条件，达成时停止。
    == AGNES
      AGNES 是一种经典的自底向上的聚类策略。它的思想是：
      - 选择一种簇的距离度量
      - 每轮迭代，合并距离最近的两个簇
      - 直到达到停止条件（例如当前簇的个数达到设定的个数）
      核心问题是如何度量两个簇的距离。常用的包括：
      - 最小距离:
        $
          min_(x in C, y in C') d(x - y)
        $
      - 最大距离:
        $
          max_(x in C, y in C') d(x - y)
        $
      - 平均距离:
        $
          1/(abs(C) abs(C')) sum_(x in C, y in C') d(x - y)
        $
      - 重心距离:
        $
          d(C, C') = d(mu_C, mu_C')
        $
      - 中心距离：
        $
          d(C, C') = d(o_C, o_C')
        $
      == 基于密度的聚类方法
        #let minPts = "minPts"
        如果将簇视作数据空间中被稀疏区域分开的稠密区域，直观上，我们可以从某个数据点的邻域出发，按照某种标准检查这个小区域是否稠密：如果稠密，则考虑将其中的点加入到当前簇中；DBSCAN 算法就是基于这种思想。它的基本思想是：
        - 设定一个半径 $epsilon$ 和最小点数 $minPts$，对于每个点 $p$，计算其邻域 $B(n, epsilon)$，如果其中的点的个数不少于 $minPts$，则称 $p$ 是一个核心点
        - 设 $x_i$ 是核心对象，$x_j in B(x_i, epsilon)$，则称 $x_j$ 是 $x_i$ 的直接密度可达点
        - 设 $x$ 是核心对象，如果存在序列 $x in {x_i} subset D$ 使得：
          $
            d(x_(i + 1), x_i) <= epsilon
          $ 
          则称所有 $x_i$ 都是 $x$ 的密度可达点
        - 称 $x, y$ 是密度相连的，如果存在 $z in D$，使得 $x, y$ 与 $z$ 分别是密度可达的
        - 容易验证，密度
= 机器学习理论
  == PAC Learnability