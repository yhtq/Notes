#import "../template.typ": *
#show: note.with(
  title: "机器学习基础",
  author: "YHTQ",
  date: datetime.today().display(),
  logo: none,
  withChapterNewPage: true
)
#let ge(h) = $R(#h)$
#let ee(h) = $hat(R)(#h)$
#let er(h) = $hat(e)_r (#h)$
#let acc(h) = $hat(a) (#h)$
= 前言  
  - 教材：周志华《机器学习》
  - 期末考试：6.10 下午，闭卷笔试
  - 作业包括纸面作业和上机作业，都在教学网进行
  - 作业/考勤 40% + 期中 20% + 期末 40%
  - 教学大纲：
    + 机器学习概论
    + 计算学习理论
    + 机器学习基本模型和算法
    + 深度学习初步
= 基本概念
  == 监督学习
    所谓监督学习，就是基于一组数据 $T = {(x_i, y_i)}$ 来学习输入空间 $X$ 到输出空间 $Y$ 的映射。通常认为样本是独立同分布的。$y_i = c(x_i)$ 有时（$c$）也称为目标概念。所有概念记为 $C$，而所有可能的概念一般记为假设空间 $H$，往往与 $C$ 不同。学习算法基于 $T$ 得到一个假设 $h_T in H$
    #definition[损失函数][
      用 $L(h(x), y)$ 度量以 $h(x)$ 作为预测的预测好坏，常见的包括：
      - 0-1 损失
        $
          L(h(x), y) = delta_(h(x), y)
        $ 
      - 平方损失
        $
          L(h(x), y) = (h(x) - y)^2
        $
    ]
    #definition[泛化误差][
      给定损失函数，则：
      $
        ge(h) = E_(x tilde D) L(h(x), c(x))
      $
      表明平均意义下预测的好坏，称其为泛化误差
    ]
    注意通常来说，$x$ 的分布 $D$ 和真实概念 $c$ 都是未知的，因此泛化误差通常是无法实际计算的。
    #definition[经验误差/测试误差][
      - 给定训练数据集 $T$，则：
        $
          ee(H) = E_T L(h(x), y_i) = 1/N sum_i L(h(x_i), y_i)
        $
        称为经验误差（经验风险）。经验误差小未必保证泛化误差小，可能产生*过拟合*现象。

        更进一步，不同的机器学习理论可能给出对：
        $
          P(abs(approxVar(R)(h_T) - R(h_T)) < epsilon) 
        $
        的估计
      - 类似的，在测试集上计算的误差称为测试误差。通常来说，测试集的产生与训练过程无关，可以认为它们独立，同时有：
        $
          E_("test") (approxVar(R)_"test" (h_T)) = R(h_T) 
        $

    ]
    #definition[误差率/准确率][
      用：
      $
        er(h_T) = E_T delta_(h(x), y_i)
      $
      表示算法在 $T$ 上的误差率。用：
      $
        acc(h_T) = 1 - er(h_T)
      $
      表示算法在 $T$ 上的准确率。
    ]
    经验误差小并不能保证泛化误差足够小。
    
    实际二分类问题中，往往会将结果分为真/T 以及假/F，因此产生四类情况：
    - TP：真正例
    - FP：假正例
    - TN：真负例
    - FN：假负例
    通常：
    - $"TP"/("TF" + "TP")$ 称为准确率/查准率
    - $"TP"/("TP" + "FN")$ 称为召回率/查全率
    一般来说，查准率和查全率是相互抵触的。


    实际训练模型中，通常来说有两种策略：
    - 经验风险最小化：最小化经验误差
    - 结构风险最小化/正则化策略：
      $
        argmin_h approxVar(R) (h) + lambda J(h)
      $
      其中 $J(h)$ 为正则化项，$lambda$ 为正则化参数。实践上，这两者的选择方法是十分复杂的。
    
    由于超参数（例如 $lambda$ ）的存在，数据往往还要分出一部分用以验证，具体来说：
    - 选取不同的超参数，在训练集上训练
    - 在验证集上验证，选取最优的超参数
    - 在测试集上测试，得到最终的对模型的评价
    #algorithm[数据集的划分][
      通过验证数据选择超参数的过程称为模型选择，基本方法有：
      - 留出法/简单交叉验证法：通过无放回的随机采样，将数据划分为训练集和验证集。有时可以采用分层采样的方式，保证数据的分布。
      - $k$ 值交叉验证法：将数据划分为 $k$ 个大小相等的子集，每次取一个子集作为验证集，其余的作为训练集，重复 $k$ 次，得到 $k$ 个模型，取平均值作为该数据集下的结果。有时，也会重复多次以增强训练的稳定性。
      - 留一法：$k = N$ 的特殊情况，每次只取一个样本作为验证集，其余的作为训练集。这种方法训练数据比较大，但计算量也很大。
      - 自助法：通过有放回的采样，得到一定大小（通常为原数据集大小）的训练集，未被抽中的元素的作为验证集。这样采样可以保证最终训练模型时数据集大小与模型选择过程中相同，但得到的分布往往和原分布有所不同。
      这些流程结束后，可以选择最优的超参数在原数据集上重新训练模型，得到最终的模型。
    ]

    #definition[][
      - 定义：
        $
          overline(h) (x) = E_T h_T (x)\
          "Bias" (x) = E_T (h_T (x) - c(x)) \
          "Var" (x) = E_T (h_T (x) - overline(h) (x))^2
        $
        其中 Bias 是指该模型预测结果与实际结果的偏差，Vars 是指该模型使用不同数据集训练时的输出方差。
    ]
    #lemma[][
      $
        E_T (h_T (x) - c(x))^2 = "Bias" (x)^2 + "Var" (x)
      $
    ]
    表明泛化误差可以分解为方差和偏差的平方和。然而，实际上偏差小（表示对数据敏感）和方差小（对数据不敏感）往往是矛盾的。模型简单时，方差较小，但拟合能力弱，偏差较大；模型复杂时，偏差小，但模型更加敏感，方差较大。

    如果数据本身就有噪声，也即：
    $
      y = c(x) + epsilon
    $
    则有：
    $
      E_(T, epsilon) (h_T (x) - y)^2 = "Bias" (x)^2 + "Var" (x) + E_(T, epsilon) (epsilon)^2
    $
= 支持向量机
  以二分类任务为例，使用最简单的线性模型，就是找一个超平面将数据分开：
  - 若假设存在这样一个超平面，如何找到？
  - 若不假设，如何找到一个最优的超平面？
  == 线性可分支持向量机
    称一个数据集 $T = {(x_i, y_i)}$，其中 $y_i in {1, -1}$ 是线性可分的，如果存在一个超平面 $w^T x + b = 0$，使得对所有的 $i$ 有 $y_i (w^T x_i + b) > 0$，该超平面称为分离超平面。

    若模型正确分类，则一定有：
    $
      y_i (w^T x_i + b) > 0, forall i
    $
    为了找到最好的超平面：
    - 由齐次性，不妨假设：
      $
        abs(w x_i + b) >= 1
      $
    - 特别的，对于 $y_i (w x_i + b) = 1$ 的样本点而言，它们就是距离超平面最近的点，而这样的点到分离平面的距离恰好为 $1/norm(w)$
    - 我们把 $2/norm(w)$ 称为*间隔*，也就是一对离超平面最近的点的距离。目标即是找到间隔最大的超平面
    因此，我们得到了优化问题：
    $
      max_(w, b) 1/(norm(w)) suchThat y_i (w^T x_i + b) >= 1, forall i 
    $
    其中 $1/(norm(w))$ 为间隔，表示超平面到最近的点的距离。它可以转化为凸优化问题：
    $
      min_(w, b) 1/2 norm(w)^2 suchThat y_i (w^T x_i + b) >= 1, forall i
    $
    这是凸二次优化问题，只要有解（原问题线性可分），则解唯一。称它的解为最大间隔分离超平面。对应的分类决策函数就是下面的“神经元”：
    $
      f(x) = sgn(w^T x + b)
    $
    为了求解这个问题，构造拉格朗日函数：
    $
      L = 1/2 norm(w)^2 - sum_(i = 1)^N alpha_i - sum_(i = 1)^N alpha_i y_i (w^T x_i + b)
    $
    求导可得：
    $
      w = sum_i alpha_i y_i x_i\
      sum_i alpha_i y_i = 0
    $
    对于非平凡的数据集，一定有 $w != 0$，因此 $alpha_i$ 不能全为零。将以上两式代回，可以证明：
    $
      L = sum_i alpha_i - 1/2 sum_(i, j) alpha_i alpha_j y_i y_j x_i^T x_j
    $
    因此原问题等价于：
    $
      max_alpha sum_i alpha_i - 1/2 sum_(i, j) alpha_i alpha_j y_i y_j x_i^T x_j \
      suchThat sum_i alpha_i y_i = 0, alpha_i >= 0
    $
    这个问题被称为原问题的对偶问题。

    由 KKT 条件，若 $alpha_i != 0$，则：
    $
      y_j (w^T x_j + b) = 1\
      b = y_j - w^T x_j = y_j - sum_(i = 1)^N alpha_i y_i x_i^T x_j
    $
    由上面的推导，往往也将支持向量机写作：
    $
      sgn(sum_i alpha_i y_i x_i^T x + b)
    $
    事实上，由 KKT 条件还有：
    $
      alpha_i (y_i (w^T x_i + b) - 1) = 0
    $
    还可以得到：
    $
      norm(w)^2 &= inner(w, sum_i alpha_i y_i x_i)\
      &= sum_i alpha_i y_i inner(w, x_i)\
      &= sum_i alpha_i y_i (y_i - b)\
      &= sum_i alpha_i y_i^2 - b sum_i alpha_i y_i\
      &= sum_i alpha_i \
    $
    因此可得间隔的表达式：
    $
      2/norm(w) = 2/(sqrt(sum_i alpha_i))\
    $
    因此，事实上我们希望不为零的 $alpha_i$ 尽可能少，这些向量就被称为支持向量。显然支持向量就是恰好成立：
    $
      abs(w^T x_i + b) = 1
    $
    的那些向量。


    可以证明，假设在训练集 $D$ 上采用留一法，定义留一误差为：
    $
      ee(f) = 1/N sumBrN1(I(f_(D^(-i)) != y_i))
    $
    则有：
    $
      ee(f) <= 1/N N_("SV")(f)
    $
    其中 $N_("SV")(f)$ 是支持向量的个数。（该估计仅做了解）
  == 非线性可分支持向量机
    在大多数时候，要求线性可分有些严苛。此时，不仅要最小间隔尽可能大，还要希望分类错误的点尽可能少。因此，我们为每个点引入松弛量 $xi_i$，约束条件变为：
    $
      y_i (w x_i + b) + xi_i >= 1
    $
    我们将 $xi_i != 0$ 的点称为特异点。如果只考虑非特异点，则情形是与线性可分情形相同的。为了区分起见，我们将此时的间隔称作软间隔，可分情形称作硬间隔。我们希望间隔尽可能小，并且特异点也要尽可能少，因此我们得到了优化问题：
    $
      min_(w, b) 1/2 norm(w)^2 + C sum_i 1_(xi_i !=0) \ 
      suchThat y_i (w x_i + b) >= 1 - xi_i, xi_i >= 0
    $
    实践上，往往采用以下的松弛版本：
    $
      min_(w, b) 1/2 norm(w)^2 + C sum_i xi_i\
      suchThat y_i (w x_i + b) >= 1 - xi_i, xi_i >= 0
    $<sv-2>
    有时也可采用 $C sum_i xi_i^p$ 作为松弛项。

    在上面的问题中，显然取 $xi_i = max(0, 1 - y_i (inner(w, x_i) + b))$ 即可。因此引入合页损失函数：
    $
      h(z) = max(0, 1 - z)
    $ 
    问题等价为
    $
      min_(w, b) 1/2 norm(w)^2 + C sum_i h(y_i (inner(w, x_i) + b))
    $
    或者：
    $
      min_(w, b) 1/2 sum_i max(0, 1 - y_i (inner(w, x_i) + b)) + 1/C norm(w)^2
    $
    事实上，这就是采取合页损失的结构风险最小化策略。事实上，之前的松弛就是用合页损失替代了 $0-1$ 损失。当然也可以采用二次损失替代合页损失。

    回到@sv-2，假如使用拉格朗日乘子法，可以得到拉格朗日函数：
    $
      L = 1/2 norm(w)^2 + C sum_i xi_i - sum_i alpha_i (y_i (inner(w, x_i) + b) - 1 + xi_i) - sum_i beta_i xi_i
    $
    求导得到：
    $
      w = sum_i alpha_i y_i x_i\
      sum_i alpha_i y_i = 0\
      alpha_i = C - beta_i
    $
    化简得到：
    $
      L = sum_i alpha_i - 1/2 sum_(i, j) alpha_i alpha_j y_i y_j inner(x_i, x_j)
    $
    因此得到对偶问题：
    $
      max_alpha sum_i alpha_i - 1/2 sum_(i, j) alpha_i alpha_j y_i y_j inner(x_i, x_j)\
      suchThat sum_i alpha_i y_i = 0, 0 <= alpha_i <= C
    $<sv-3>
    可以看到，形式上只是增加了约束 $alpha_i <= C$，同时许多结论仍然成立：
    - 仍然可以将 $alpha_j > 0$ 的点称为支持向量
    - $w = sum_i alpha_i y_i x_i$
    - $b = y_i - sum_j alpha_j y_j inner(x_j, x_i)$
    - 在所有的支持向量中，$0 < alpha_i < C$ 的点落在分类边界上，$alpha_i = C$ 的点是特异点。
    可以证明，最优平面的法向量 $w$ 是唯一的，但偏置 $b$ 往往不唯一，需要后续实验确认，或者多次求值后取平均
  == SMO 算法
    Platt 提出的*序列最小最优化算法（SMO）*可以高效地解决@sv-3 这种二次规划问题。其基本思想是：
    - 将多个拉格朗日乘子的问题化减到仅有两个乘子的问题。往往，我们选择第一各变量是违反 KKT 条件最严重的，第二个变量是使得目标函数增加最快的。
    - 仅有两个乘子的二次规划问题有解析解
    首先考虑仅有两个乘子的问题求解：
    #algorithm[][
      假设当前只更新拉格朗日乘子 $alpha_1, alpha_2$，约束：
      $
        sum_i alpha_i y_i = 0
      $
      给出：
      $
        alpha_1 y_1 + alpha_2 y_2 = - sum_(i != 1, 2) alpha_i y_i\
        alpha_1 + alpha_2 y_1 y_2 = - y_1 sum_(i != 1, 2) alpha_i y_i
      $
      令 $s = y_1 y_2, gamma = - y_1 sum_(i != 1, 2) alpha_i y_i$，则原问题转化为
      $
        max_(alpha_1, alpha_2) W(alpha_1, alpha_2)\
        suchThat 0 <= alpha_1, alpha_2 <= C, alpha_1 + s alpha_2 = gamma
      $
      事实上，使用 $alpha_1 = gamma - s alpha_2$ 代换后，这就是关于 $alpha_2$ 的一元二次函数，可以直接求最大值。

      注意每次更新 $alpha_1, alpha_2$ 后，都需要更新 $b$. 若 $alpha_1, alpha_2$ 中至少一个非零，则应该采用 $b = y_j - inner(sum_i alpha_i y_i x_i, x_j)$ 更新
    ]
    - 选择需要更新的变量：往往选择违反 KKT 条件最严重的变量，第二个变量选择一个使得目标函数增加最快的变量
  == 核方法 
    许多问题是完全不能依靠线性函数划分的。一个很自然的想法是构造映射 $phi$，使得 $phi(X)$ 线性可分。得到最优化问题：
    $
      min_(w, b, xi) 1/2 norm(w)^2 + C sum_i xi_i\
      suchThat y_i (inner(w, phi(x_i)) + b) >= 1 - xi_i, xi_i >= 0
    $
    或者对偶问题：
    $
      max_alpha sum_i alpha_i - 1/2 sum_(i, j) alpha_i alpha_j y_i y_j inner(phi(x_i), phi(x_j))\
      suchThat sum_i alpha_i y_i = 0, 0 <= alpha_i <= C
    $
    实际应用上，$phi$ 是难以构造的。经典的处理方式是引入*核函数*：观察上面的对偶问题，事实上我们不关系 $phi$ 的具体值，只关心：
    $
      K(x_1, x_2) = inner(phi(x_1), phi(x_2))
    $
    在数据集上的值，因此合理选择核函数即可，最终的分类函数形如：
    $
      f(x) = sgn(sum_i alpha_i y_i K(x_i, x) + b)\
      b = y_j - sum_i alpha_i y_i K(x_i, x_j)
    $
    往往我们会选择正定对称的核函数，常用的包括：
    - 线性核函数：$K(x, z) = inner(x, z)$
    - 多项式核函数：$K(x, z) = (inner(x, z) + 1)^p$
    - 高斯核函数：$K(x, z) = exp(-d(x, z)^2 / (2 sigma^2))$
= 基于后验概率最大化准则的分类模型
  之前我们的思路是学习得到一个预测函数。我们也可以采取其他思路：给定数据集 $T$，我们希望学习得到一个概率分布 $P(y | x)$，并通过该分布下后验概率最大的 $y$ 作为预测值。
  == 分类准则
    设 $y$ 的可能值为 $autoRListN(c, n)$，如果给定一个损失函数 $l(y, y')$，定义将 $x$ 预测为 $c_i$ 的风险（期望损失）为：
    $
      R(y = c_i | x) = sum_(j = 1)^n l(c_i, c_j) P(y = c_j | x)
    $
    最优（风险最小）的预测为：
    $
      hat(y) = argmin_(c_i) R(y = c_i | x)
    $
    如果采取 0-1 损失，不难验证：
    $
      R(y = c_i | x) = 1 - P(y = c_i | x)
    $
    显然，此时损失最小等价于 $argmax_(c_i) P(y = c_i | x)$，也就是后验概率最大准则。

    通常而言，贝叶斯模型分为判别式模型和生成式模型：
    - 判别式模型：直接建模 $P(y | x)$，例如逻辑回归
    - 生成式模型：建模 $P(x | y)$，然后通过贝叶斯公式计算 $P(y | x)$
  == 逻辑斯谛回归
    #definition[二阶逻辑斯谛回归][
      设 $x$ 为 $n$ 维向量，$y$ 为二分类变量，$P(y = 1 | x) = p(x)$，则称以下分布：
      $
        P(y = c_1 | x) = e^(w^T x + b) / (1 + e^(w^T x + b))\
        P(y = c_2 | x) = 1 / (1 + e^(w^T x + b))
      $
      是二阶逻辑斯谛回归模型，其中 $w$ 是参数，$b$ 是偏置。事实上，这相当于二元形式的 softmax 函数。
    ]
    事实上，对于给定的 $x$，将其分到 $c_1$ 还是 $c_2$ 取决于 $w x + b$ 的正负，因此最终判断的准则是线性的（由于是取对数后得到线性函数，因此也称为*对数线性模型*）

    给定数据集，最常见的参数估计方法就是最大似然估计，也就是希望：
    $
      argmax_(w, b) = L(w, b) = prodi1N(P(y_i | x_i))
    $
    可以计算得：
    $
      ln L(theta) = sumi1N(y_i (w^T x_i + b) - ln(1 + e^(w^T x_i + b)))
    $
    该方程没有解析解，但根据偏导为零，可以求得：
    $
      sumi1N(x_i (y_i - p(y_i = 1 | x_i, w, b))) = 0\
      sumi1N(y_i - p(y_i = 1 | x_i, w, b)) = 0
    $
  == 朴素贝叶斯模型
    贝叶斯公式给出：
    $
      P(y = c_i | x) = (P(x | y = c_i) P(y = c_i)) / sumk1M(P(x | y = c_k) P(y = c_k))
    $
    而分母实际上不影响我们分类，因此我们的任务是：
    - 从数据集得到 $Y$ 和 $X | Y$
    - 从贝叶斯公式计算得到 $Y | X$
    假定 $X$ 是离散的，可能取值为 $N$，则理论上，只需要估计 $N M$ 个参数，但是这个量往往过大。所谓朴素贝叶斯，就是认为 $X$ 分成多个相互独立的特征 $X_1, X_2, ..., X_n$，因此：
    $
      P(X = x | y) = prodi1n(P(X_i = x_i | y))
    $
    假设第 $i$ 个特征有 $m_i$ 个取值，独立性假定将参数量从 $M(prodi1n(m_i))$ 降低到了 $M(sumi1n(m_i))$，显然有大幅度的下降。类似的，我们还是使用极大似然估计，事实上由于是离散值，因此就是直接使用频率估计：
    $
      P(y = c_k) = sum_(y = c_k) 1/N\
      P(X_i = x_(i j) | y = c_k) = (sum_(X_i = x_(i j), y = c_k) 1)/(sum_(y = c_k) 1)
    $
    由此计算后验概率，注意到后验概率与 $P(x | y = c_i) P(y = c_i)$ 成正比，因此类别预测准则为：
    $
      y = argmax_(c_i) P(y = c_i) prodi1n(P(X_i = x_i | y = c_i))
    $
    注意在这样的估计中，可能将某个参数估计为零，导致多个概率相乘仍是零。因此有改进方法：
    - 使用：
      $
        ((sum_(X_i = x_(i j), y = c_k) 1) + lambda)/((sum_(y = c_k) 1) + lambda m_j)
      $
      矫正 $P(X | Y)$
    - 使用：
      $
        ((sum_(y = c_k) 1) + lambda)/(N + lambda M)
      $
      矫正 $P(Y)$
    简单来说，就是对每个频数加一个 $lambda$ 扰动。$lambda = 1$ 时称为 Laplace 平滑，实际上这与所谓的*贝叶斯估计*的结果是一致的。
= 基于近邻的分类方法
  这类方法又称为免模型方法或者惰性学习，最终得到的不是一个显式的模型，而是根据新样本落在哪一类作为预测结果。这类方法的核心问题包括：
  - 如何度量数据的相似性
  - 选择哪些与新数据相似的实例
  - 如何利用选定样本的类标记来预测新数据的类标记
  在特征空间为 $RR^n$ 的情况下，最常用的距离度量是 MinKowski 距离。给定度量，我们有经典的 k-近邻法：
  - 基于度量，对于任意 $x$ 找出训练集中与 $x$ 最近的 $k$ 个点，这些点构成邻域 $N_k^(dist)$，其中的类标签采用简单投票多数占优原则。
  - 经验风险为：
    $
      1/k sum_(x_i in N_k^dist) I(y_i != y)
    $
    其中 $y$ 是选择的类标签。
  一般来说，$k$ 值小时模型方差大，$k$ 值大时模型偏差大，实践上往往从较小的 $k$ 开始，逐渐增大，直到模型的性能不再提升为止。

  当 $k = 1$ 时，该方法称为最近邻法。某种意义上，最近邻法相当于将空间按照最靠近的点做了划分，每个划分单元赋予一个类标签。
  == K-Means 方法
    一个自然的想法是，能否将数据集中靠近的样本合并，再用一个点替代。K-Means 方法就是找到 $k$ 个这样的点：
    - 选择任意 $k$ 个初始点
    - 将每个点划分到离它最近的点，构成 $k$ 元的划分
    - 对每个划分，计算其中心，用该中心替代原来的初始点
    - 重复进行直至收敛
    完成聚类后，再将得到的 $k$ 个类作为最近邻法的数据集进行分类。$k-$ 近邻法的缺陷是，代表点离分类边界很近时，很容易分类错误。
  == 学习向量量化方法
    学习向量量化方法是对 K-Means 方法的改进，设样本空间为 $X$，则它使用 $X^k$ 而非 $X$ 作为类中心点的标记：
    - 初始时，在每个类 $c_m$ 中选择 $k$ 个点构成该类的代表向量：
      $
        autoRVecN(I^m, k)
      $
    - 随机选取一个样本，找到最近的代表点 $I^i_j$
      - 若该样本的类别是 $i$，则更新：
        $
          I^i_j = I^i_j + eta (x - I^i_j)
        $
      - 否则，更新：
        $
          I^i_j = I^i_j - eta (x - I^i_j)
        $
      其中 $eta in (0, 1)$ 是预先确定的学习率
    - 重复进行，直到收敛
    可以注意到，在更新过程中，如果同类别，就有：
    $
      norm(x - (I^i_j + eta (x - I^i_j))) = (1 - eta) norm(x - I^i_j) <= norm(x - I^i_j)
    $
    如果不同类别，就有：
    $
      norm(x - (I^i_j - eta (x - I^i_j))) = (1 + eta) norm(x - I^i_j) >= norm(x - I^i_j)
    $
= 决策树方法
  对于分类问题，我们也可以采用决策树方法，根据规则对数据进行分类。大致算法是将数据根据某个特征分成树，直到无特征可用时，用剩余数据的最多的样本值作为该分支的样本值。
  == 基本决策树
  #definition[经验熵][
    定义训练集的经验熵如下：
    $
      H(D) = - sumBrN1(p_i log_2 p_i) where p_i = abs(D_i)/abs(D)
    $
    它度量了数据集的“纯度”，经验熵越大，数据集的信息量越大。可以证明在 $p_i$ 都相等的时候，经验熵最大。
  ]
  #definition[][
    对于特征 $A$，其对数据集 $D$ 的经验条件熵定义为：
    $
      H(D|A) = sumk1m(abs(D_k^A)/abs(D) H(D^A_k))
    $
    其中 $D_k^A$ 是 $D$ 中所有特征 $A$ 取 $k$ 的数据。
    进一步，定义信息增益为：
    $
      G(D, A) = H(D) - H(D|A)
    $
  ]
  直观来说，我们应该向着信息增益越大的方向分类。然而，信息增益有一个缺点，它偏向于选择取值较多的特征。因此，我们可以引入校正项：
  #definition[][
    定义信息增益比：
    $
      G(D, A) =( H(D) - H(D|A)) / H(A)
    $
    其中 $H(A)$ 是特征 $A$ 的熵（也称分裂信息/固有值） $- sumk1m(abs(D^A_k)/abs(D) log_2 abs(D^A_k)/abs(D))$。信息增益比越大，表明特征 $A$ 的分类能力越强。
  ]
  注意增益比会偏好取值少的特征，因此实践上往往选取增益比高于某个阈值的，信息增益最大的特征。

  除了使用熵作为指标，还可以选择其他的指标：
  #definition[][
    定义基尼指数：
    $
      "Gini"(D) = 1 - sumBrN1(p_i^2)
    $
    它相当于从数据集中随机抽取两个样本，类别不一致的概率。基尼指数越小，数据集的纯度越高。

    类似的，定义特征 $A$ 对数据集 $D$ 的基尼指数：
    $
      "Gini"(D, A) = sumk1m(abs(D_k^A)/abs(D) "Gini"(D^A_k))
    $
    它越小，表明特征 $A$ 的分类能力越强。
  ]
  选定一个指标 $F$，我们就可以设计一般的决策树算法：
  + 若样本集 $D$ 中所有元素属于同一类别 $C$，则返回单节点树 $T$
  + 若 $A = emptyset$，且 $D$ 非空，则生成以 $D$ 中样本数最多的类别 $C$ 为标记的节点
  + 否则，计算所有特征 $A$ 对数据集 $D$ 的度量，选择最优特征 $A_*$，划分数据集 $D$ 为 $D_1, D_2, ..., D_n$，对于每个 $D_i$ 递归生成决策树
  历史上，选择信息增益最大的算法称为 ID3 算法，选择信息增益比最大的算法称为 C4.5 算法，选择基尼指数最小的算法称为 CART 算法。注意 ID3, C4.5 算法中，我们对 $A$ 的每个取值做多路划分，而 CART 只对 $A = a_i, A eq.not a_i$ 做二路划分，选择特征时也要选择最优的划分点。显然多路划分得到的决策树更小，但实践表明其泛化能力和二路划分差别不大。

  然而，决策树也可能产生“过拟合”，因此我们希望对决策树进行剪枝，以达到某种结构风险最小。大致分为两种策略：
  - 预剪枝策略：在生成过程中，基于验证集对当前划分做出评估，如果泛化能力未提升则直接标记为叶节点。然而，这种方法相当于提前禁止一些分支展开，可能会导致欠拟合。
  - 后剪枝策略：生成完成后，对决策树进行剪枝，根据验证集比较剪枝后的树和原树的泛化能力，选择最优的树。这种方法相对来说更加保守，但是也更加稳定。
  同时，后剪枝策略也可以采取正则化方法。给定一个决策树 $T$，可以将损失函数定为：
  $
    C_alpha(T) = C(T) + alpha abs(T)
  $
  其中 $C(T)$ 是拟合程度，例如：
  $
    C(T) = sum_(t = 1)^abs(T) N_t H_t (T)
  $
  其中 $N_t$ 是叶节点 $t$ 的样本数，$H_t (T)$ 是叶节点 $t$ 的经验熵（事实上 $C(T)$ 接近于负的对数似然函数）。$alpha$ 是正则化参数，用以平衡拟合程度和模型复杂度。

  CART 算法有特别的剪枝处理方式，会产生一个递增的权衡系数序列和对应的最优子树（依次嵌套），将会使用交叉验证法来选择其中最优的一个。

  有时，我们也会遇到特征连续的数据。此时，常用策略是对于每个特征，列出出现在数据集中的所有情况，取所有中点作为划分点。

  另外，有时会出现有数据的某些特征缺失的情况。典型的处理方法是：
  - 使用对样本加权的方式计算占比和熵
  - 选择特征时，用 $"该特征未缺失数据占比" times "在该数据未缺失数据构成的数据集上的信息增益"$ 作为信息增益
  - 划分数据时，若该特征缺失，则将数据等权重的划分到所有子节点中
  == 最小二乘回归树
    有时，我们也可以使用决策树进行回归。对于回归问题，我们可以使用最小二乘回归树。其基本思想是将输出函数变成阶梯形：
    $
      f(x) = sum_(m = 1)^M c_m 1_(x in R_m)
    $
    其中 $R_m$ 是选定的单元，通常 $c_m$ 就是 $R_m$ 中所有数据的均值（这样可以达到最小的最小二乘误差）。只要选定 $R_m$，问题就变成了分类问题。具体操作如下：
    - 选择一个特征 $j$ 和一个切分点 $s$，将数据集划分为 $R_1(j, s) = {x|x_j <= s}$ 和 $R_2(j, s) = {x|x_j > s}$，使得：
      $
        min_(c_1) sum_(x_i in R_1) (y_i - c_1)^2 + min_(c_2) sum_(x_i in R_2) (y_i - c_2)^2
      $
      最小。（显然上式中 $c_1, c_2$ 的最优值就是 $R_1, R_2$ 中所有数据的均值）
    - 基于上面的 $j, s$，将数据集划分为 $R_1, R_2$，重复上述过程，直到达到停止条件。
    类似的，我们也可以仿照前面的思想进行剪枝。采用损失函数：
    $
      C_alpha (T) = C(T) + alpha abs(T)
    $
    其中：
    $
      C(T) = sum_(t = 1)^abs(T) N_i Q_i (T)\
      where Q_t (T) = 1/N_t sum_(x_i in R_t) (y_i - c_t)^2
    $
  == 小结
    - 决策树模型是基于特征对实例进行分类的树形结构。
    - 学习算法往往采用贪心策略
    - ID3 算法，C4.5 算法，CART 算法是常见的决策树学习算法，分别采用信息增益最大，信息增益比最大，基尼指数最小作为特征选择准则。
    - ID3 算法，C4.5 算法采用多路划分，CART 算法采用二路划分。
    信息熵、条件信息熵的计算需要掌握。期中考试的内容到此为止。
= 神经网络学习初步
  == M-P 神经元模型，多层前馈神经网络
    前面的许多机器学习模型可以表达为线性模型和非线性模型的组合。也就是，先计算一个线性结果，再使用非线性的激活函数处理线性结果，这就是一个 M-P 神经元。
    #definition[Sigmoid][
      定义：
      $
        f(x) = 1/(1 + exp(-x))
      $
      为 Sigmoid 函数，它是一个很传统的激活函数。
    ]
    #definition[多层前馈神经网络][
      称：
      - 神经元逐层排列，相邻层神经元全连接，不相邻层无连接
      - 第一层为输入层，最后一层为输出层，中间层为隐藏层
      - 除输入层外，每层都通过激活函数处理输入
    ]
    通常而言，宽度和深度都能增加神经网络的表达能力，但深度往往更加经济。
    
    前面讨论的支持向量机模型可以看作是无隐藏层，采用符号函数作为激活函数的神经网络。对于单隐层前馈神经网络，可以写出模型的表达式：
    $
      Y = sigma(V sigma(W X + gamma) + theta)
    $
    可以计算得，单隐藏层前馈网络的参数集为：
    $
      (Union_(t = 1)^m {w_(j t)}_(j = 1)^n) union Union_(l=1)^k {v_(t l)}_(t = 1)^m union {theta_l}_(l=1)^k union {gamma_t}_(t = 1)^m
    $
    其中 $gamma, theta$ 分别是隐藏层，输出层的偏置。总计 $(n + k + 1) m + k$ 个参数。

    对于损失函数，经典的经验风险最小化策略是，用平方误差度量输出层在数据集上的损失，也就是：
    $
      R(Theta) = norm2(Y - hY)
    $
    训练时，往往采用梯度下降策略，有：
    $
      der(R(Theta), hY) = 2 (hY - Y)^T \
    $
    如果使用 Sigmoid 函数作为激活函数，则：
    $
      der(sigma(y), y) = sigma(y) (1 - sigma(y))\
    $
    因此：
    $
      der(hY, V sigma(W X +gamma) + theta) = (sigma(V sigma(W X +gamma) + theta) (1 - sigma(V sigma(W X +gamma) + theta))) dot *\
    $ 
    通常记 $delta = 2(hY - Y) dot (sigma(V sigma(W X +gamma) + theta) (1 - sigma(V sigma(W X +gamma) + theta)))$，被称为误差项。

    给定学习率 $eta$，标准的梯度下降算法如下：
    $
      x = x - eta der(R(x), x)\
    $
    同时，通常选择参数时，不会选择零值而是靠近零的随机值作为参数初始值，避免所有信号全为零。从根本上，这是因为 Sigmoid 函数具有某种饱和性，因此现代神经网络往往不再使用 Sigmoid 函数，而是使用其他激活函数。
    #example[常用激活函数][
      - 整流线性函数 RELU:
        $
          f(x) = max(0, x)
        $
      - 带泄漏的整流线性函数 Leaky RELU:
        $
          f(x) = max(0, x) + alpha min(0, x)
        $
    ]

    实际训练时，往往采用*批量*随机下降法，也就是将数据分成不同的部分，每次使用一个批量进行参数更新。
= 集成学习
  有时，单个的学习器未必效果较好。通过将相对比较容易构建但泛化能力一般的多个学习器进行结合，可能得到更好的泛化能力，这种思想称为*集成学习*
  
  根据集成学习中个体分类器是否由统一算法得到的，将集成学习分为同质的和异质的：
  - 对于同质的集成学习，每个学习器都由同一学习算法获得，相应的个体学习器称为基学习器，学习算法为基学习算法
  - 反之就是异质的，并称相应的个体学习器为组件学习器

  此外，根据个体学习器的组件之间关系，将集成学习分为序列化方法和并行化方法：
  - 有依赖性的个体学习器只能串行学习，例如提升方法
  - 无依赖关系的个体学习器可以并行学习，例如 Bagging 方法，随机森林
  == 提升方法
    #definition[弱学习算法][
      若某算法的平均误差好于随机猜测，则称该算法为弱学习算法
    ]
    #definition[强学习算法][
      若当样本数量充分大时，平均误差以大概率任意小，则称该算法为强学习算法
    ]
    理论上可以证明，在 PAC 框架下一个问题是强可学习的当且仅当是弱可学习的，但在实践中设计弱学习算法往往更容易一些，因此将弱学习算法提升得到强学习算法的方法称为提升方法。
    #algorithm[Adaboost][
      对于二分类问题，采用加权多数表决的方式对若干个依次学到的同质的弱分类器进行集成。这是一种序列化方法，投票权重由该学习器的性能决定。具体来说：
      - 给定数据集 $D, y in {-1, 1}$
      - 第 $t$ 轮时，用 $w_(i t)$ 作为第 $t$ 轮时数据 $i$ 的权重，用来保证得到的弱分类器不同
      - 通常取 $w_(i 1) = 1/N$，之后的权值由之前轮学习器得到的结果进行调整
      - 第 $t$ 轮时，按照：
        $
          f_t = argmin_f sumi1N(w_(i, t) I(f(x_i) != y_i))\
        $
        得到该轮的基分类器 $f_t$
      - 计算 $f_t$ 的分类错误率：
        $
          e_t = sum_(i=1)^N w_(i, t) I(f_t (x_i) != y_i)\
        $
        以此计算 $f_t$ 在加权投票中的权值：
        $
          alpha_t = 1/2 ln((1 - e_t)/e_t)\
        $
      - 同时，采用如下方法更新 $W$:
        $
          w_(i, t + 1)' = w_(i, t) e^(- alpha_t y_i f_t (x_i))\
          w_(i, t + 1) = w_(i, t + 1)'/sumj1N(w_(j, t + 1)')\
        $
      - 经过 $T$ 轮学习后，按照：
        $
          G(x) = sgn(sum_(t = 1)^T alpha_t f_t (x))
        $
        进行预测。
      注意在序列学习中，未必保证每一轮都比上一轮好，只是保证最后的结果比单个弱学习器好。

      此外，注意到：
      $
        Z_t &:= sumj1N(w_(j, t + 1)') = sumj1N(w_(j, t)) e^(- alpha_t y_j f_t (x_j))\
        &= sum_(y_i != f_t (x_i)) w_(i, t) e^(alpha_t) + sum_(y_i = f_t (x_i)) w_(i, t) e^(-alpha_t)\
        &= e_t e^(alpha_t) + e^(-alpha_t) (1 - e_t)\
      $
      可以证明上式恰为：
      $
        Z_t = 2 sqrt(e_t(1 - e_t))
      $
      
      理论上可以证明，只要 $e_t$ 都小于 $1/2$，得到的结果就是强学习算法。如果在实际使用时出现 $e_t >= 1/2$，需要额外处理。一种处理方法时到该步就放弃，另一种方法是重新采样数据重新开始。

      最终有：
      $
        hat(R)(f) &= 1/N sumi1N(I(y_i G(x_i)) <= 0)\
        &<= 1/N sumi1N(e^(-y_i G(x_i)))\
        &= product_(t = 1)^T Z_t\
        &= product_(t = 1)^T 2 sqrt(e_t (1 - e_t))\
        &= product_(t = 1)^T sqrt(1 - 4 (1/2 - e_t)^2)\
        &<= e^(-2 sum_(t = 1)^T (1/2 - e_t)^2)
      $
      假设存在 $gamma$ 使得 $1/2 - e_t >= gamma$，就有：
      $
        hat(R)(f) <= e^(-2 T gamma^2)
      $
      表明误差以负指数速度快速下降。
    ]

    #definition[加法模型][
      设 $f_i$ 是若干基分类器，则：
      $
        G(x) = sum_(t = 1)^T alpha_t f_t (x)
      $
      称为一个加法模型。
    ]
    显然，上面的 Adaboost 方法就是加法模型的一种。事实上，我们如果假设使用指数损失函数 $e^(-y f(x))$，则第 $t$ 步时，就是要求：
    $
      argmin_(alpha, f) 1/N sum_(i = 1)^N e^(-y_i (G_(t - 1) (x_i) + alpha f(x_i)))
    $
    可以计算得：
    $
      G_t (alpha, f) = product_(s = 1)^(t - 1) Z_s (sum_(i = 1)^N w_(i, t) e^(-y_i alpha f(x_i)))
    $
    记 $e_t = sum_(y_i != f(x_i)) w_(i, t)$，不难求得：
    $
      f_t = argmin_f e_t\
      alpha = 1/2 ln((1 - e_t)/e_t)
    $
    这就是 Adaboost 算法的结果。
    #algorithm[提升树模型][
      设 $T(x)$ 是基决策树，构造目标加法模型：
      $
        f(x) = sum_(m = 1)^M T(x)
      $
      构造方法为给定损失函数 $L$，则第 $m$ 个基学习器由以下经验风险最小化学得：
      $
        T_m = argmin_f 1/N sum_(i=1)^N L(y_i, f_(m - 1) (x_i) + f(x_i))
      $
      事实上，就是拟合目前剩余的残差。
    ]
  == Bagging 与随机森林
    对训练样本进行重采样，利用不同的样本数据来学习不同的基学习器，降低方差是一类典型的思路，Bagging 算法就是其中的代表。
    #algorithm[Bagging][
      Bagging 算法的流程如下：
      - 每次从 $N$ 个样本的训练数据集中利用自助法，得到 $N$ 个采样
      - 训练 $M$ 个基学习器，每个基学习器在不同的采样上进行训练
      - 对每个基学习器的预测结果进行投票或平均，得到最终的预测结果
      典型的，对于样本 $x_i$，称未使用 $x_i$ 进行训练的基学习器的预测结果作为*包外预测*
    ]
    #algorithm[随机森林][
      在 Bagging 算法的基础上引入随机属性选择，就得到了随机森林模型。所谓随机选择特征是指，决策树在选择划分特征时，先从当前结点的所有特征（不妨设为 $d$ 个特征）中选择 $k$ 个作为候选，再从 $k$ 个特征中选择最优划分。
      - 当 $k = d$ 时，则随机森林模型就是基学习算法采用决策树的 Bagging
      - 当 $k < d$ 时，相当于在特征选择时引入随机波动
      - 当 $k = 1$ 时，相当于随机选择一个特征
      参数 $k$ 在实践上一般推荐 $k = log_2 d$

      随机森林方法比单纯的 Bagging 方法增加了基学习器的多样性差异，然而每个基学习器训练时因为选择特征变少，理论性能可能降低。随着基学习器数目的增加，随机森林通常会收敛到比 Bagging 更低的泛化误差。
    ]
= 聚类算法\*  
  聚类是一种典型的无监督学习问题，目标是将数据集划分为若干个簇，使得同一簇内的样本相似度高，而不同簇之间的样本相似度低。
  == K-Means 算法
    K-Means 算法是最常用的聚类算法之一。它的基本思想是：
    - 选择 $k$ 个初始簇心
    - 将每个样本分配到离其最近的簇心所在的簇
    - 更新每个簇的簇心为该簇内所有样本的均值
    - 重复上述过程，直到簇心不再变化或达到最大迭代次数

    K-Means 算法的优点是简单易实现，计算效率高，但缺点是需要预先指定聚类个数 $k$，且对初始簇心敏感（一般对多个初始簇心运行多次）。此外，K-Means 算法采用平方误差作为度量，这对非凸的数据分布可能不适用。同时，均值运算对异常点相对比较敏感。

    对于一般的度量 $d$，我们也可以对其设计 K-Means 算法，计算时类 $C$ 中心点就是：
    $
      argmin sum_(x in C) d(x, mu_C)
    $

    此外还有一种变体称为 PAM （围绕中心点的划分算法）。它的思想是：
    - 初始随机初始化簇心
    - 每次迭代，对每个簇心 $o_I$，考虑所有其他样本点 $x_i$，评估用 $x_i$ 代替作为簇新能否得到更好的划分。如果可以，就将其作为新的簇心，将数据重新划分。
    - 重复尝试直到划分不再变化
    这种算法将数据点作为簇心，而不是计算平均值，相对而言对异常点不敏感。
  == 高斯混合模型
    高斯混合模型是假定数据满足高斯分布和的聚类方法，也即：
    $
      p(x) = sum(i = 1)^k alpha_i N(x, mu_i, Sigma_i)
    $
    其中 $N(x, mu_i, Sigma_i)$ 是联合分布函数，我们称之为第 $i$ 个分模型。它可以理解为，对于数据 $x_j$，先构造一个随机变量 $z_j$ 使得：
    $
      P(z_j = i) = alpha_i
    $
    之后，间接确定 $x_j$ 的分布：
    $
      p(x_j | z_j = i) = N(mu_i, Sigma_i)
    $
    假设模型给定，要判断数据来自哪个簇就是要求出后验概率最大化：
    $
      argmax_i P(z_j = i | x_j) = argmax_i (alpha_i N(x_j, mu_i, Sigma_i))/(sum_(s = 1)^k P(x_j | z_s = s) alpha_s)
    $
    它们的分母是一致的，只需求：
    $
      argmax_i alpha_i N(x_j, mu_i, Sigma_i)
    $

    对于一组数据，如何求出它的模型呢？直观的想法是采用对数似然函数，但这实际求解起来很困难。对于此类问题，通常采用 EM 算法（期望最大化算法）来求解。

  == EM 算法
    对于一类含有隐变量的模型，EM 算法是常见的求解策略。通常来说，目标是最大化：
    $
      L(theta) = ln sum_z P(y, z | theta)
    $
    使用迭代方法，假设 $theta^i$ 已经确定，可以证明：
    $
      L(theta) >= L(theta^i) + sum_z p(z | y, theta^i) ln(p(y, z | theta)/(p(z | y, theta^i) p(y | theta^i)))\
    $
    我们的策略是转化为令上式右侧最大，等价于让：
    $
      sum_z p(z | y, theta^i) ln(p(y, z | theta)) = E_z (ln p(y, z | theta) | y, theta^i)
    $
    最大。求解该优化问题就得到的 $theta^(i + 1)$。一般，称求期望的步骤为 $E$ 步，称最大化的步骤为 $M$ 步。

    EM 算法对于初始值是相当敏感的，因此往往会多次求解选择最优的结果。此外，EM 算法也不能保证收敛到最优点，但可以保证似然函数的值单调递增。

    对于高斯混合模型，我们采用以下扩充的隐变量：
    $
      z_(j i) = ite(z_j = i, 1, 0)
    $
    如此，可以计算：
    $
      E_z (ln p(y, z | theta) | y, theta^i) = sum_(i = 1)^k ((sum_(j = 1)^N E z_(j i)) ln alpha_i + sum_(j = 1)^N (E z_(j i)) ln N(x_j, mu_i, Sigma_i))
    $
    经过一些计算，就可以得到最终更新参数的方式。
  == 层次聚类方法
    之前提到的模型都是一致的聚类方法，聚类个数不变。如果在聚类过程中动态的调整聚类个数，就称为层次聚类方法。层次聚类方法分为自底向上和自顶向下两种：
    - 将所有样本视作一个簇，逐步拆分成更小的簇的方法称为自顶向下的方法
    - 将每个样本视作一个簇，逐步合并成更大的簇的方法称为自底向上的方法
    通常来说，层次聚类方法不用事先设定聚类个数，而是设定一个停止条件，达成时停止。
    == AGNES
      AGNES 是一种经典的自底向上的聚类策略。它的思想是：
      - 选择一种簇的距离度量
      - 每轮迭代，合并距离最近的两个簇
      - 直到达到停止条件（例如当前簇的个数达到设定的个数）
      核心问题是如何度量两个簇的距离。常用的包括：
      - 最小距离:
        $
          min_(x in C, y in C') d(x - y)
        $
      - 最大距离:
        $
          max_(x in C, y in C') d(x - y)
        $
      - 平均距离:
        $
          1/(abs(C) abs(C')) sum_(x in C, y in C') d(x - y)
        $
      - 重心距离:
        $
          d(C, C') = d(mu_C, mu_C')
        $
      - 中心距离：
        $
          d(C, C') = d(o_C, o_C')
        $
      == 基于密度的聚类方法
        #let minPts = "minPts"
        如果将簇视作数据空间中被稀疏区域分开的稠密区域，直观上，我们可以从某个数据点的邻域出发，按照某种标准检查这个小区域是否稠密：如果稠密，则考虑将其中的点加入到当前簇中；DBSCAN 算法就是基于这种思想。它的基本思想是：
        - 设定一个半径 $epsilon$ 和最小点数 $minPts$，对于每个点 $p$，计算其邻域 $B(n, epsilon)$，如果其中的点的个数不少于 $minPts$，则称 $p$ 是一个核心点
        - 设 $x_i$ 是核心对象，$x_j in B(x_i, epsilon)$，则称 $x_j$ 是 $x_i$ 的直接密度可达点
        - 设 $x$ 是核心对象，如果存在序列 $x in {x_i} subset D$ 使得：
          $
            d(x_(i + 1), x_i) <= epsilon
          $ 
          则称所有 $x_i$ 都是 $x$ 的密度可达点
        - 称 $x, y$ 是密度相连的，如果存在 $z in D$，使得 $x, y$ 与 $z$ 分别是密度可达的
        - 容易验证，密度
= 隐马尔可夫模型
  == 马尔可夫链
    #definition[][
      设 $X_t$ 是随机变量的序列，如果 $X_(t + 1)$ 与 $X_1, ..., X_(t - 1)$ 都独立，且 $X_(t + 1) | X_t$ 与 $X_2 | X_1$ 同分布，则称之为（时齐）的马尔可夫链。
    ]
    假设 $X_t$ 都在离散空间 $S$ 中取值，则 $X_t$ 的分布可以被 $RR^S$ 中向量代表。进一步，按照定义，应该有：
    $
      P(X_(t + 1) = s) = sum_(k in S) P(X_t = k) P(X_(t + 1) = s | X_t = k) \
      = sum_(k in S) P(X_t = k) P(X_2 = s | X_1 = k)
    $
    因此 $X_(t + 1)$ 的概率向量是 $X_t$ 的一个与 $t$ 无关的线性变换 $P$，我们也将 $P$ 称为转移矩阵，事实上：
    $
      P_(s t) = P(X_(t + 1) = t | X_t = s)
    $
    显然 $P$ 的行求和为 $1$
  == 隐马尔可夫模型
    在实际应用中，通常不一定能观测到马尔可夫链的状态序列。
    #definition[隐马尔可夫模型][
      假设 $O_t$ 是一个随机变量序列，称其的一个隐马尔可夫模型是指：
      - 不可观测的马尔可夫序列 $X_t$，其状态空间为 $S$
      - 已知的分布 $O_t | X_t$，并且 $O_t | X_t$ 独立于之前的 $O$ 与 $X$
    ]
    假设 $O_t$ 的取值空间为 $R$，则我们可以构造观测概率矩阵：
    $
      B = (P (O_t = r | X_t = s))_(r in R, s in S)
    $
    如果假设 $B$ 与 $t$ 无关，则 $A, B$ 和 $X_0$ 的初始分布 $pi$ 就确定了一个隐马尔可夫模型。隐马尔可夫模型中，变量之间的依赖关系可以用一个图来表示，因此也称为概率图模型。隐马尔可夫模型中，研究的问题包括：
    - 概率计算：给定模型，计算任意观测序列出现的概率
    - 解码问题：给定模型和观测序列，计算最有可能的隐变量序列 $X$
    - 学习问题：给定观测序列，估计最有可能的隐马尔可夫模型
  == 概率计算
    当然，观测序列出现的概率可以直接计算，但隐变量序列的数量过大，直接计算不可接受。我们可以通过动态规划的思想，合并重复计算。

    一种想法是前向算法：定义
    $
      alpha_t (s) = P(O_1, O_2, ..., O_t, X_t = s)
    $
    自然的有递推式：
    $
      alpha_(t + 1) (s) = sum_(s' in S) alpha_t (s') P(O_(t + 1), X_(t + 1) = s | O_1, O_2, ..., O_t, X_t = s')\
      = sum_(s' in S) alpha_t (s') P(O_(t + 1) | O_1, O_2, ..., O_t, X_t = s', X_(t + 1) = s) P(X_(t + 1) = s | O_1, O_2, ..., O_t, X_t = s')\
      = sum_(s' in S) alpha_t (s') P(O_(t + 1) | X_(t + 1) = s) P(X_(t + 1) = s | X_t = s')\
    $
    上式中都是已知量，因此可以计算。

    另一种想法是后向算法：定义
    $
      beta_t (s) = P(O_(t + 1), O_(t + 2), ..., O_T | X_t = s)
    $
    就有：
    $
      beta_t (s) = sum_(s' in S) P(O_(t + 1), O_(t + 2), ..., O_T | X_t = s, X_(t + 1) = s') P(X_(t + 1) = s' | X_t = s)\
      = sum_(s' in S) P(X_(t + 1) = s' | X_t = s) \
      P(O_(t + 2), O_(t + 3), ..., O_T | X_(t + 1) = s', X_t = s) P(O_(t + 1) | O_(t + 2), O_(t + 3), ..., O_T X_(t + 1) = s', X_t = s)\
      = sum_(s' in S) P(O_(t + 2), O_(t + 3), ..., O_T | X_(t + 1) = s') P(O_(t + 1) | X_(t + 1) = s') P(X_(t + 1) = s' | X_t = s)\
      = sum_(s' in S) beta_(t + 1) (s') P(O_(t + 1) | X_(t + 1) = s') P(X_(t + 1) = s' | X_t = s)\
    $
  == 维特比算法
    解码问题相当于求：
    $
      argmax_X P(X | O)
    $
    事实上，如果把所有 $X_1, X_2, ..., X_T$ 的取值排列起来，相邻层之间连线，则一个 $X$ 相当于在图中选取一条极大路径，解码问题就是求关于这个路径的某种最大值。采用动态规划思想，定义：
    $
      delta_t (s) = max_(X_1, X_2, ..., X_(t - 1)) P(X_1, X_2, ..., X_t = s, O_1, O_2, ..., O_t)
    $
    我们就有递推公式：
    $
      delta_t (s) = max_(s' in S) max_(X_1, X_2, ..., X_(t - 2)) P(X_1, X_2, ..., X_(t - 1) = s', X_t = s, O_1, O_2, ..., O_t)\
      max_(s' in S) max_(X_1, X_2, ..., X_(t - 2)) P(X_t = s, O_t | X_1, X_2, ..., X_(t - 1) = s', O_1, O_2, ..., O_(t - 1)) P(X_1, X_2, ..., X_(t - 1) = s', O_1, O_2, ..., O_(t - 1))\
      max_(s' in S) max_(X_1, X_2, ..., X_(t - 2)) P(X_t = s, O_t | X_(t - 1) = s') delta_(t - 1) (s')\
      max_(s' in S) max_(X_1, X_2, ..., X_(t - 2)) P(X_t = s| X_(t - 1) = s') P(O_t | X_t = s) delta_(t - 1) (s')\
    $
    其中，取最大的 $s'$ 可以记录下来，后续可以回溯。
  == Baum-Welch 算法
    对于隐马尔可夫链，我们可以使用 EM 算法迭代求解，这就是 Baum-Welch 算法。其中，$Q$ 函数被定义为：
    $
      Q(lambda, lambda') = sum_X P(X | O, lambda') log P(O, X | lambda)\
      = sum_X P(X  O | lambda')/P(O | lambda') log P(O, X | lambda)
    $
    由于目标是 $argmin_lambda$，因此索性直接使用 $Q$ 函数为：
    $
      sum_X P(X  O | lambda') log P(O, X | lambda)
    $
= PAC 理论
  == 可实现性假设
    #let ERM = "ERM"
    本节中，我们假设 $X$ 服从某个固定的未知分布 $D$，并记：
    - 泛化误差：
      $
        L_(D, f) (h) = P_(x tilde D) (h(x) != f(x))
      $
    - 训练误差：
      $
        L_S (h) = 1/m sum_(i = 1)^m 1_(y_i != h(x_i))\
      $
    - Hypothesis class: 一类假设函数的集合
    最普遍的想法是，给定一个函数类 $H$ 和训练集 $S$，找出其中训练误差最小的函数作为模型，这种方法称为 ERM 学习器，也即：
    $
      ERM_H (S) = argmin_(h in H) L_S (h)\
    $
    当然，上面的方程可能有多个解，我们往往用 $h_S$ 记某个符合最优化条件的解。
    #definition[Realizability Assumption][
      若 $H$ 满足：
      $
        exists h^* in H, L_(D, f) (h^*) = 0
      $
      则称可实现性假设成立。
    ]
    #corollary[][
      若可实现性假设成立，则以概率一有：
      - $L_S (h^*) = 0$
      - $L_S (h_s) = 0$
    ]
    #proof[
      注意到以概率 $1$ 有：
      $
        h^* (x_i) = y_i, forall i = 1, ..., m\
      $
      换言之，$L_S (h^*) = 0$，而 $L_S (h_s) <= L_S (h^*)$
      因此结论显然
    ]
    #theorem[][
      假设 $H$ 是有限假设类，设 $delta in (0, 1), epsilon > 0, m$ 是一整数满足：
      $
        m >= (ln (abs(H) / delta)) / epsilon
      $
      则对于任何函数 $f$，任何分布 $D$ 满足可实现性假设成立，假设样本集是规模为 $m$ 的独立同分布样本 $S$，我们有：
      $
        P_S (L_(D, f) (h_S) <= epsilon) >= 1 - delta
      $
    ]
    #proof[
      记：
      $
        H_B = {h in H | L_(D, f) (h) > epsilon}\
        M = {S | exists h in H_B, L_S (h) = 0}
      $
      注意到：
      $
        {S | L_(D, f) (h_S) > epsilon} subset M = union_(h in H_B) {S | L_S (h) = 0}\
      $
      因此：
      $
        P_S (L_(D, f) (h_S) > epsilon) 
        &<= P_S (exists h in H_B, L_S (h) = 0)\ 
        &= P_S (sum_(h in H_B) L_S (h_S) = 0) \
        &<= sum_(h in H_B) P_S (L_S (h_S) = 0)\
        &= sum_(h in H_B) product_(i = 1)^m P_(x_i tilde D) (h(x_i) = f(x_i))\
        &= sum_(h in H_B) product_(i = 1)^m P_(x tilde D) (h(x) = f(x))\
        &= sum_(h in H_B) product_(i = 1)^m (1 - L_(D, h) (h))\
        &<= sum_(h in H_B) product_(i = 1)^m (1 - epsilon)\
        &<= sum_(h in H_B) (1 - epsilon)^m\
        &<= abs(H) (1 - epsilon)^m\
        &<= abs(H) e^(-m epsilon)\
        &<= delta\
        \
      $
      证毕
    ]
  == PAC 可学习性
    #definition[PAC 可学习性][
      称一个假设类 $H$ 是 PAC 可学习的，如果存在一个函数 $m_H : (0, 1) -> (0, 1) -> NN$ 以及一个学习算法满足：
      #align(center)[
        对于任何 $delta, epsilon in (0, 1)$，任何 $X$ 上的分布 $D$ 以及标签函数 $f : X -> {0, 1}$，只要 $H, D, f$ 满足可实现性假设，则选择任何样本数量 $m >= m_H (epsilon, delta)$ 独立同分布训练集，算法会给出一个假设 $h$ 使得 $P_S (L_(D, f) (h) <= epsilon) >= 1- delta$
      ]
    ]
    大致来讲，一个 PAC(Probably Approximately Correct) 可学习类是指存在一个算法，对于任何满足可实现性的 $D, f$，只要样本数量充分大，算法会训练得到一个模型使得该模型泛化误差较大的可能性充分小。
    #definition[Sample complexity][
      对于一个 PAC 可学习性中的算法，称 $m_H (epsilon, delta)$ 为该算法的样本复杂度，它度量了我们至少需要多少样本才能达到充分近似。对于同一个算法显然存在多个样本复杂度，我们称最小的样本复杂度为所有可能选择中的最小值
    ]
    #corollary[][
      设 $H$ 是有限假设类，则它是 PAC 可学习的，且其样本复杂度:
      $
        m_H (epsilon, delta) <= (ln (abs(H) / delta)) / epsilon
      $
    ]
    需要注意的是，并非所有 PAC 可学习性都是有限的。
  == 不可知 PAC 可学习性
    之前我们都是在可实现性假设下讨论问题。然而在实际的学习任务中，可实现性假设往往是过强的。为了放弃可实现性假设，我们引入了不可知 PAC 可学习性(Agnostic PAC Learning)的概念。同时，我们也放松标签函数的要求，不要求每个 $x$ 唯一确定一个 $y$，而是假设存在 $x, y$ 的联合分布，用 $P(y | x)$ 表示对某个 $x$ 取 $y$ 标签的概率。自然的，重新定义泛化误差为：
    $
      L_D (h) = P_((x, y) tilde D) (h(x) != y)
    $
    目标仍是选择一个函数 $h : X -> Y$ 使得泛化误差最小。
    #theorem[Bayes Optimal Predictor][
      假设 $Y = {0, 1}$，则最优预测函数就是：
      $
        f_D (x) = cases(
          1 "if" P(y = 1 | x) >= 1/2,
          0 "else"
        )
      $
      它被称为*贝叶斯最优预测器*
    ]
    注意通常来说，$D$ 是未知的，因此无法计算 $f_D$，目标转而变为选择一个预测器，其性能尽可能接近 $f_D$。
    #definition[不可知 PAC 可学习性][
      称一个假设类 $H$ 是不可知 PAC 可学习的，如果存在一个函数 $m_H : (0, 1) -> (0, 1) -> NN$ 以及一个学习算法满足：
      #align(center)[
        对于任何 $delta, epsilon in (0, 1)$，任何 $X times Y$ 上的分布 $D$，选择任何样本数量 $m >= m_H (epsilon, delta)$ 独立同分布训练集，算法会给出一个假设 $h$ 使得 $P_S (L_D (h) <= min_(h' in H) L_D (h') + epsilon) >= 1- delta$
      ]
    ]
    不可知 PAC 可学习性是 PAC 可学习性的推广。在可实现性假设成立时，它和通常的 PAC 可学习性是等价的。

    接下来，我们把结论推广到一般的损失函数：
    #definition[损失函数][
      对于 $H, X$，称 $l$ 是一个损失函数，如果 $l(h, x) >= 0$
    ]
    以及：
    - 风险函数：
      $
        L_D (h) = E_(x tilde D) (l(h, x))\
      $
    - 经验风险函数：
      $
        L_S (h) = 1/m sum_(i = 1)^m l(h, x_i)\
      $
    #definition[一般损失函数的不可知 PAC 可学习性][
      称一个假设类 $H$ 是使用损失函数 $l$ 的意义下不可知 PAC 可学习的，如果存在一个函数 $m_H : (0, 1) -> (0, 1) -> NN$ 以及一个学习算法满足：
      #align(center)[
        对于任何 $delta, epsilon in (0, 1)$，任何 $Z$ 上的分布 $D$，选择任何样本数量 $m >= m_H (epsilon, delta)$ 独立同分布训练集，算法会给出一个假设 $h$ 使得 $P_S (L_D (h) <= min_(h' in H) L_D (h') + epsilon) >= 1- delta$，其中 $L_D (h) = E_(z tilde D) l(h, z)$ 是损失函数
      ]
    ]
  == 一致收敛性
    #definition[$epsilon-$ representative][
      称一个训练集 $S$ 是 $epsilon-$ representative，如果对于任意的 $h$，都有：
      $
        abs(L_S (h) - L_D (h)) <= epsilon
      $
    ]
    #lemma[][
      设训练集 $S$ 是 $epsilon/2-$ representative，则：
      $
        L_D (h_S) <= min_(h in H) L_D (h) + epsilon
      $
    ]
    #proof[
      $
        L_D (h_S) 
        &<= L_S (h_S) + epsilon/2\
        &<= min_h L_S (h) + epsilon/2\
        &<= min_h L_D (h) + epsilon\
      $
    ]
    #definition[一致收敛性][
      称一个假设类 $H$ 是有一致收敛性质的，如果存在一个函数 $m_H : (0, 1) -> (0, 1) -> NN$ 满足：
      #align(center)[
        对于任何 $delta, epsilon in (0, 1)$，任何 $Z$ 上的分布 $D$，对于样本数量 $m >= m_H (epsilon, delta)$ 独立同分布训练集，它至少 $1 - delta$ 的概率是 $epsilon-$ representative 的
      ]
    ]
    #lemma[][
      设 $H$ 是一致收敛的，对应函数为 $M_H^("UC")$，则 $H$ 是不可知 PAC 可学习的，且其样本复杂度：
      $
        m_H (epsilon, delta) <= ceil(M_H^("UC") (epsilon/3, delta))
      $
      并且此时，ERM 就是不可知 PAC 可学习中一个可选择的算法
    ]
    #lemma[][
      设 $H$ 是有限假设类，则 $H$ 是具有一致收敛性的，其样本复杂度：
      $
        m_H^("UC") (epsilon, delta) <= ceil((ln (2 abs(H) / delta)) / (2 epsilon^2))
      $
      进而，它是不可知 PAC 可学习的，且其样本复杂度：
      $
        m_H (epsilon, delta) <= ceil((ln (2 abs(H) / delta)) / (epsilon^2))
      $
    ]
    #proof[
      我们需要利用下面的不等式：
      #theorem[Hoeffding's inequality][
        设 $X_1, X_2, ..., X_m$ 是 $[a, b]$ 上的独立同分布随机变量，$mu = E(X_i)$，则对于任意 $epsilon > 0$，都有：
        $
          P(abs(1/m sum_(i = 1)^m X_i - mu) > epsilon) <= 2 e^(-(2 m epsilon^2)/(b - a^2))
        $
      ]
      任取 $epsilon, delta$，我们只要找到对应的 $m$ 即可。注意到：
      $
        P_S (exists h in H, abs(L_S (h) - L_D (h)) > epsilon) <= sum_(h in H) P_S (abs(L_S (h) - L_D (h)) > epsilon)\
      $
      Hoeffding's inequality 给出：
      $
        P_S (abs(L_S (h) - L_D (h)) > epsilon) <= 2 e^(-2m epsilon^2)
      $
      因此上式：
      $
        <= 2 abs(H) e^(-2m epsilon^2)\
      $
      因此只要：
      $
        m >= (ln (2 abs(H) / delta)) / (2 epsilon^2)\
      $
      就有结论成立。
    ]
== Bias-Complexity Tradeoff
  #theorem[No-Free-Lunch][
    设 $A$ 是任何 $X$ 上二分类问题的学习算法，$m <= abs(X) / 2$ 作为训练样本数量，则存在 $X times {0, 1}$ 上一个分布 $D$ 使得：
    - 存在函数 $f : X -> {0, 1}$ 使得 $L_D (f) = 0$
    - $P_S (L_D (A(S)) >= 1/8) >= 1/7$
  ]
  #corollary[][
    设 $X$ 是无穷集，$H = X -> {0, 1}$，则 $H$ 不是 PAC 可学习的
  ]
  #proof[
    如若不然，选择 $epsilon < 1/8, delta < 1/7$，则存在学习算法 $A$，整数 $m$ 使得任何 $X times {0, 1}$ 上分布 $D$ 都有：
    $
      P_S (L_D (A(S)) >= 1/8) < 1/7 + min_(h in H) L_D (h) + epsilon\
    $
    然而，选择 No-Free-Lunch 定理中的分布 $D$ 和函数 $f$，注意到：
    $
      min_(h in H) L_D (h) <= L_D (f) = 0 => min_(h in H) L_D (h) = 0\
      P_S (L_D (A(S)) >= 1/8) >= 1/7\
    $
    矛盾！
  ]
  通常来说，我们会对泛化误差考虑分解：
  $
    L_D (h_S) = (L_D (h_S) - min_(h in H) L_D (h)) + (min_(h in H) L_D (h))\
  $
  或者对于二分类问题：
  $
    L_D (h_S) - L_D (f_D) = (L_D (h_S) - min_(h in H) L_D (h)) + (min_(h in H) L_D (h) - L_D (f_D))
  $
  通常记:
  $
  epsilon_("app") = min_(h in H) L_D (h)
  $（或者 $(min_(h in H) L_D (h) - L_D (f_D))$），称为*近似误差*，它度量了我们选择的假设类 $H$ 和真实的标签函数 $f_D$ 之间的差距。而：
  $
    epsilon_("est") = L_D (h_S) - min_(h in H) L_D (h)
  $
  称为*估计误差*，它度量了训练集导致的最优损失函数的偏差。对于有限的 $H$，$epsilon_("est")$ 关于 $abs(H)$ 对数增加，关于 $m$ 减少。

  上面的分解表明，当 $H$ 选择的足够大时，近似误差很小，但可能导致估计误差很大，此时称为*过拟合*；当 $H$ 选择的足够小，估计误差很小，但可能导致近似误差很大，此时称为*欠拟合*。因此，选择一个合适的假设类 $H$ 是非常重要的。
  == VC-维数
    #definition[Shattering][
      设 $H$ 是一个假设类，$C subset X$ 是有限集，称 $H$ shatters $C$，如果 $H$ 在 $C$ 上的限制包含了所有 $C -> {0, 1}$ 的函数。
    ]
    #corollary[][
      设 $H$ 是一个假设类，$m$ 是训练集大小。假设存在 $2 m$ 元集合 $C$ 使得 $X$ shatter $C$，则对于任何学习算法 $A$，存在 $X times {0, 1}$ 上的分布 $D$ 和 $h in H$ 使得 $L_D (h) = 0$，但：
      $
        P_(S tilde D^m) (L_D (A(S)) >= 1/8) >= 1/7
      $ 
    ]<No-Free-Lunch-2>
    #let VCdim = "VCdim"
    #definition[VC 维数][
      对假设类 $H$，记 $VCdim(H)$ 是元素最多的被 $H$ shattered 的有限集的大小（可能为无穷）
    ]
    #lemma[][
      $VCdim(H) = d$ 当且仅当存在一个大小为 $d$ 的集合 $C$ 使得 $H$ shatters $C$，并且不存在大小为 $d + 1$ 的集合 $C'$ 使得 $H$ shatters $C'$。
    ]
    #corollary[][
      设 $H$ 有限，则：
      $
        VCdim(H) <= log_2 (abs(H))\
      $
    ]
    #definition[增长函数][
      设 $H$ 是一个假设类，则定义 $H$ 的增长函数：
      $
        tau_H (m) = max_(C subset X, |C| = m) abs(H_C)\
      $
      其中 $H_C$ 是 $H$ 在 $C$ 上的限制
    ]
    #corollary[][
      若 $VCdim(H) = d$，则 $forall n < d, tau_H (n) = 2^n$
    ]
    #lemma[Sauer-Shelah-Perles][
      设 $VCdim(H) = d < +infinity$，则：
      $
        tau_H (m) <= sum_(i = 0)^d C_m^i
      $
      特别的，若 $m > d + 1$，则：
      $
        tau_H (m) <= ((e m) /d)^d
      $
    ]<Sauer-Shelah-Perles>
    #theorem[][
      对于任何分布 $D, delta > 0, h$ 有：
      $
        P_(S tilde D^m) (
          abs(
            L_D (h) - L_S (h) <= (4 + sqrt(ln (tau_H (2 m))))/(delta sqrt(2 m))
          )
        ) >= 1 - delta
      $
    ]<VC-dim-inequality>
    #theorem[][
      $H$ 是 PAC-可学习的当且仅当 $VCdim(H) < +infinity$
    ]
    #theorem[The Fundamental Theorem os Statistical Learning][
      设 $H$ 是一个假设类，损失函数选取 $0-1$ 损失，则以下说法等价：
      - $H$ 具有一致收敛性质
      - ERM 是一个不可知 PAC 可学习的算法
      - $H$ 是不可知 PAC 可学习的
      - $H$ 是 PAC 可学习的
      - ERM 是一个 PAC 可学习的算法
      - $VCdim(H) < +infinity$
      这个定理还有量化版本，各个性质对应的样本复杂度都可以被 $d$ 刻画。
    ]<Fundamental-Theorem-of-Statistical-Learning>
    #proof[
      我们只证明若 $d < +infinity$，则 $H$ 有一直收敛性之。由 @Sauer-Shelah-Perles 我们有对 $m > d$:
      $
        tau_H (2 m) <= ((2 e m) / d)^d\
      $
      结合 @VC-dim-inequality，就有以至少 $1 - delta$ 的概率：
      $
        abs(L_D (h) - L_S (h)) <= (4 + sqrt(d ln ((2 e m) / d)))/(delta sqrt(2 m))\
      $
      不妨设 $sqrt(d ln ((2 e m))) >= 4$，则：
      $
        abs(L_D (h) - L_S (h)) <= 1/delta (sqrt((2 d ln ((2 e m) / d)) / m))\
      $
      代入一致收敛性的定义，可以验证只需：
      $
        m >= (2 d ln m)/(delta^2 epsilon^2) + (2 d ln (2 e quo d))/(delta^2 epsilon^2)\
      $
      尽管式子右侧还有 $ln m$，但 $m$ 的增长远快于 $ln m$，因此可以解出一个与 $m$ 无关的下界使得上式成立，就有原结论成立。
      
    ]
  == 非一致可学习性
    之前我们定义不可知 PAC 可学习性时，我们要求对于任何 $h in H$ 都有：
    $
      L_D (A(S)) <= L_D (h) + epsilon
    $
    我们可以稍微放松要求，对于固定的 $h' in H$，要求当 $m$ 充分大时，有：
    $
      P_S (L_D (A(S)) <= L_D (h') + epsilon) >= 1 - delta
    $
    换言之，$m$ 可以额外依赖 $h'$，这就放松了不可知 PAC 可学习性的要求。
    #definition[非一致可学习性][
      称一个假设类 $H$ 是非一致可学习的，如果存在一个函数 $m_H : (0, 1) -> (0, 1) -> NN$ 以及一个学习算法满足：
      #align(center)[
        对于任何 $delta, epsilon in (0, 1), h' in H$，任何 $X times Y$ 上的分布 $D$，选择任何样本数量 $m >= m_H^("NUL") (epsilon, delta, h')$ 独立同分布训练集，算法会给出一个假设 $h$ 使得：
        $
        P_S (L_D (h) <= L_D (h') + epsilon) >= 1- delta
        $
      ]
    ]
    #theorem[][
      假设 $H_n$ 是至多可数个假设类，其中每个 $H_n$ 都满足一致收敛性，则 $H = union_(n = 1)^infinity H_n$ 是非一致可学习的
    ]
    #theorem[][
      $H$ 是非一致可学习的当且仅当可以写成不可知 PAC 可学习的假设类的至多可数并集。
    ]
    #proof[
      只证明必要性。考虑：
      $
        H_n = {h in H | m_H^("NUL") (1/8, 1/7, h) <= n}\
      $
      显然 $H = union_n H_n$，根据 @Fundamental-Theorem-of-Statistical-Learning，只需证明每个 $H_n$ 都是 PAC 可学习的。事实上，假设可实现性假设成立，就有：
      $
        P_(S tilde D^n) (L_D (h_S) <= 1/8) >= 1 - 1/7\
      $
      考虑 @No-Free-Lunch-2，上式蕴含着 $VCdim(H) < +infinity$，因此结论成立。
    ]
    #example[][
      设 $H_n$ 是不超过 $n$ 次多项式分类器组成的空间。可以证明 $VCdim(H_n) = n + 1$，但 $VCdim(union_n H_n) = +infinity$，因此 $union_n H_n$ 是非一致可学习的，但不是不可知 PAC 可学习的。
    ]
    #theorem[][
      假设 $w : NN -> [0, 1]$ 是权重函数满足 $sum_n w(n) <= 1, H = union_n H_n$ 其中 $H_n$ 是一致收敛的，定义：
      $
        epsilon_n (m, delta) = min {epsilon in (0, 1) | m_(H_n)^"UC" (epsilon, delta) <= m}
      $
      则对任意的 $delta, D$，有：
      $
        P_(S tilde D^m) (
          forall n, h in H_n,
          abs(L_D (h) - L_S (h)) <= epsilon_n (m, w(n)  delta)
        ) >= 1 - delta
      $
      也就是：
      $
        P_(S tilde D^m) (
          forall h in H,
          abs(L_D (h) - L_S (h)) <= min_(n, h_n in H_n) epsilon_n (m, w(n) delta)
        ) >= 1 - delta
      $
    ]
    #proof[
      记 $delta_n = w(n) delta$，则 $sum_n (delta_n) <= delta$，由一致收敛性，可设：
      $
        P(A_n) = P(forall h in H_n, abs(L_D (h) - L_S (h)) <= epsilon_n (m, delta_n)) >= 1 - delta_n\
      $
      因此：
      $
        P(product_n A_n) >= 1 - sum_n P(A_n^c) >= 1 - sum_n delta_n = 1 - delta\
      $
    ]
    以上的定理表明，非一致可学习性类可以与结构风险最小化策略对应，其中 $w(n)$ 就反映了先验知识对不同的 $H_n$ 的偏好。
    #definition[SRM 策略][
      在上面定理的假设下，对于给定的训练集 $S$ 和置信度 $delta$，找到一个 $h$ 使得：
      $
        h in argmin_(h in H) (L_S (h) + epsilon_n (m, w(n) delta)) where n = min_n h in H_n
      $
      的策略称为*结构风险最小化(SRM)策略*
    ]
    #theorem[][
      若 $w(n) = 6/(n^2 pi^2)$，则 $H$ 在 SRM 策略下是非一致可学习的，且样本复杂度：
      $
        m_H^"NUL" (epsilon, delta, h) <= m_(H_n)^"UC" (epsilon/2, (6 delta)/((pi n)^2)) where n = min_n h in H_n
      $
    ]

= 奇异值分解和主成分分析
  == 奇异值分解
    对于任何实矩阵，我们从 $A^T A$ 是实对称矩阵，进而可正交对角化出发。熟知 $ker A^T A = ker A$，因此我们可取得 $ker A$ 的正交补空间 $M$，设 $v_1, v_2, ... v_r$ 是$M$ 的一组标准正交基，使得 $A^T A$ 在其上是对角的。令：
    $
      u_i = (A v_i) / norm(A v_i)
    $ 
    则：
    $
      inner(u_i, u_j) = inner(A v_i, A v_j) / (norm(A v_i) norm(A v_j)) = inner(v_i, A^T A v_j) / (norm(A v_i) norm(A v_j)) = lambda_j inner(v_i, v_j) / (norm(A v_i) norm(A v_j))\
    $
    再注意到：
    $
      norm(A v_i) = sqrt(quadFormSym(v_i, A^T A)) = sqrt(lambda_i)
    $
    因此：
    $
      lambda_j inner(v_i, v_j) / (norm(A v_i) norm(A v_j)) = delta_(i, j)
    $
    因此 $u_i in im A$ 非零且标准正交，再由维数可知它们构成了 $im A$ 的一组标准正交基。同时，熟知：
    $
      orthogonalCom(im A) = ker A^T
    $
    因此，再取 $u_(r + 1), ..., u_m$ 构成 $ker A^T$ 的正交基，就有：
    $
      A (v_1, v_2, ..., v_r, v_(r + 1), ..., v_n) = (sqrt(lambda_i) u_i)_(i <= r) directSum 0\
      = ((directSum_(i = 1)^r sqrt(lambda_i) I) directSum 0) (u_1, u_2, ..., u_r, u_(r + 1), ..., u_m)\
    $
    换言之：
    $
      A = U Sigma V^T
    $
    其中， $U, V$ 是正交阵，$Sigma = diag(sqrt(lambda_i))_(m times n)$. 这里，$sqrt(lambda_i)$ 称为 $A$ 的奇异值，$U$ 的列向量称为 $A$ 的左奇异向量，$V$ 的列向量称为 $A$ 的右奇异向量。
    #lemma[][
      $
        A = sum_(i = 1)^r sigma_i u_i v_i^T
      $
    ]
    #proof[
      任取 $x = sum_(i = 1)^n v_i v_i^T x = sum_(i = 1)^n (v_i^T x) v_i$，我们有：
      $
        A x = sum_(i = 1)^n (v_i^T x) (A v_i)\
        = sum_(i = 1)^r (v_i^T x) (A v_i)\
        = sum_(i = 1)^r sigma_i (v_i^T x) u_i\
        = sum_(i = 1)^r sigma_i (u_i v_i^T) x\
        = (sum_(i = 1)^r sigma_i u_i v_i^T) x\
      $
    ]
    #definition[][
      设：
      $
        U_r = (u_1, u_2, ..., u_r)_(m times r)\
        V_r = (v_1, v_2, ..., v_r)_(n times r)\
        Sigma_r = diag(sqrt(lambda_i))_(r times r)\
      $
      则引理给出：
      $
        A = U_r Sigma_r V_r^T = sum_(i = 1)^r sigma_i u_i v_i^T\
      $
      这被称为紧奇异值分解。若将 $r$ 换成 $< r$ 的 $k$，就得到了 $A$ 的截断奇异值分解。
    ] 
  == 矩阵近似
    #lemma[][
      $
        norm(A)_F = sqrt(sum_(i = 1)^n sigma_i^2)\
      $
    ]
    #proof[
      $
        norm(A)_F = norm(U Sigma V^T)_F = norm(Sigma)_F = sqrt(sum_(i = 1)^n sigma_i^2)\
      $
    ]
    #definition[][
      设 $rank(A) = r$，对于 $k < r$，定义 $A$ 的以 $k$ 为秩的最优近似是所有 $rank(M) <= k$ 的矩阵 $M$ 中：
      $
        norm(A - M)_F
      $
      取最小的矩阵。
    ]
    #lemma[][
      设 $u_i$ 是一组标准正交的向量，$lambda_i > 0$ 依次增加，$alpha_i in M$ 是秩为 $k$ 的子空间，则：
      $
        sum_(i = 1)^n norm2(lambda_i u_i - alpha_i) >= sum_(i = k + 1)^n lambda_i^2 
      $
    ]
    #proof[
      设 $P$ 是到 $span(u_i)$ 的投影，就有：
      $
        sum_(i = 1)^n norm2(lambda_i u_i - alpha_i) >= sum_(i = 1)^n norm2(lambda_i u_i - P alpha_i)
      $
      因此，不妨设 $alpha_i in span(u_i)$. 定义变换：
      $
        P_(i j) x = x + (inner(x, u_i) - inner(x, u_j)) u_j + (inner(x, u_j) - inner(x, u_i)) u_i\
        S_t^(i j) x = x + t inner(x, u_i) u_j\
      $
      则不难验证 $P_(i j), S_k^(i j)$ 是可逆变换。
      
      注意到目标函数恰为：
      $
        sum_(i = 1)^n lambda_i^2 + sum_(i = 1)^n norm2(alpha_i) - 2 lambda_i inner(u_i, alpha_i)\
        = sum_(i = 1)^n lambda_i^2 + sum_(i = 1)^n sum_(j = 1)^n inner(alpha_i, u_j)^2 - 2 lambda_i inner(u_i, alpha_i)
      $
      可不妨设：
      $
        sum_(i = 1)^n norm2(lambda_i u_i - P_(s t) alpha_i) >= sum_(i = 1)^n norm2(lambda_i u_i - alpha_i)
      $
      也即：
      $
        lambda_s inner(u_s, alpha_s) + lambda_t inner(u_t, alpha_t) >= lambda_t inner(u_s, alpha_t) + lambda_s inner(u_t, alpha_s)
      $
      由 $lambda$ 的顺序，这表明：
      $
        i > j => inner(u_i, alpha_i) <= inner(u_j, alpha_j)
      $
      另外，考虑：
      $
        sum_(i = 1)^n norm2(lambda_i u_i - S_k^(s t) alpha_i) = sum_(i = 1)^n k^2 inner(alpha_i, u_s) + 2 k inner(alpha_i, u_s) inner(alpha_i, u_t) - 2 lambda_t k inner(u_t, alpha_s) + C
      $
      不妨设上式在 $k = 0$ 取得最小（否则对 $alpha$ 进行变换使得原式变小），也即：
      $
        sum_(i = 1)^n inner(alpha_i, u_s) inner(alpha_i, u_t) = lambda_t inner(u_s, alpha_t)\
        sum_(s = 1)^n inner(alpha_s, u_i) inner(alpha_s, u_j) = lambda_j inner(u_i, alpha_j)\
      $
      类似的，考虑：
      $
        norm2(lambda_i u_i - (alpha_i + t alpha_j)) = t^2 norm2(alpha_j) + 2 t inner(lambda_i u_i - alpha_i, alpha_j) + norm2(lambda_i u_i - alpha_i)\
      $ 
      不妨设 $t = 0$ 时取最小值，就有：
      $
        inner(lambda_i u_i - alpha_i, alpha_j) = 0, forall i, j\
      $
      因此：
      $
        lambda_i inner(u_i, alpha_j) = inner(alpha_i, alpha_j) = sum_(s = 1)^n inner(u_s, alpha_i) inner(u_s, alpha_j)\
      $
      换言之，设有矩阵 $A = (inner(alpha_i, u_j))$，则：
      $
        A A^T = (lambda_i inner(alpha_j, u_i)) = Sigma A^T \
        A^T A = (lambda_j inner(u_i, alpha_j)) = A^T Sigma
      $
      其中 $Sigma = {lambda_i}$. 将有：
      $
        A A^T = Sigma A^T = A Sigma 
      $
      
      根据奇异值分解，设：
      $
        A = U Lambda V^T
      $
      则：
      $
        U Lambda^2 U^T = Sigma V Lambda U^T\
        (U Lambda - Sigma V) Lambda = 0\
        (A - Sigma) V Lambda = 0\
        V Lambda^2 V^T = V Lambda U^T Sigma\
        Lambda (U^T Sigma - Lambda V^T) = 0\
        Lambda U^T (A - Sigma) = 0
      $
      换言之，可设：
      $
        Lambda - U^T Sigma V =  U^T (A - Sigma) V = mat(0_k, 0;0, C)\
        U^T Sigma V = Lambda - mat(0_k, 0;0, C) = mat(Lambda_k, 0;0, C)
      $
      同时，回顾目标式恰为：
      $
        norm(A - Sigma)_F = norm(U^T (A - Sigma) V)_F = norm(C)_F
      $
      检查奇异值，就有：
      $
        norm(C)_F >= sum_(i = k + 1)^n lambda_i^2
      $
      证毕
    ]
    #theorem[][
      设 $A = sum_(i = 1)^r sigma_i u_i^T v_i$，其中 $sigma_i$ 按从大到小排序，则 $k$ 最优近似恰为：
      $
        A_k = sum_(i = 1)^k sigma_i u_i v_i^T
      $
    ]
    #proof[
      任取 $M$ 满足 $rank(M) <= k$，有：
      $
        norm(A - M)_F^2 
        &= sum_(i = 1)^r norm2((A - M) v_i)+ sum_(i = r + 1)^n norm2(M v_i) \ 
        &>=  sum_(i = 1)^r norm2(sigma_i u_i - M v_i)\
      $
      问题相当于
    ]
  == 总体主成分分析
    #definition[主成分变换][
      设 $X$ 是均值为 $mu$，协方差矩阵为 $Sigma$ 的随机向量，设：
      $
        A^T Sigma A = Lambda
      $
      是对角线递降的对角矩阵，$A = (alpha_1, alpha_2, ..., alpha_m)$ 为正交矩阵。则线性变换：
      $
        Y = A^T (X - mu)
      $
      称为主成分变换。其第 $i$ 个分量称为 $X$ 的第 $i$ 主成分。不难计算：
      $
        E Y = 0\
        var Y = A^T Sigma A = Lambda\
      $
    ]
    注意到，对于任何向量 $alpha$ 有：
    $
      var alpha^T (X - mu) = alpha^T Sigma alpha
    $
    换言之，$alpha_1$ 就是全空间中使得 $var alpha^T (X- mu)$ 最大的 $alpha, alpha_2$ 就是 $alpha_1$ 的正交补中使得 $var alpha^T (X - mu)$ 最大的 $alpha$，依次类推。换言之，主成分变换就是将 $X$ 投影到协方差矩阵的特征向量上。
    #definition[][
      称 $X$ 第 $k$ 主成分的方差贡献率为：
      $
        n_k = lambda_k / (sum_(i = 1)^m lambda_i)
      $
      累计方差贡献率为：
      $
        n_(1 -> k) = sum_(i = 1)^k n_i = sum_(i = 1)^k lambda_i / (sum_(j = 1)^m lambda_j)
      $
      称 $y_k$ 与 $x_i$ 的相关系数为因子负荷量，定义前 $k$ 个主成分 $y_1, y_2, ..., y_k$ 对原有变量 $x_i$ 的贡献率为：
      $
        v_(1 -> k) (i) = sum_(j = 1)^k rho^2(y_j, x_i) 
      $
    ]
  == 样本主成分分析
    设 $X = (X_1, X_2, ..., X_n)$ 是对某个随机向量独立观测得到的样本。先对数据做规范化，规范化数据仍记为 $X$，此时样本协方差矩阵：
    $
      S = 1/(n - 1) X X^T
    $
    要进行主成分分析，只需要对 $S$ 进行对角化即可。事实上，如果定义：
    $
      X' = 1/sqrt(n - 1) X^T
    $
    则 $X'$ 的奇异值就是 $S$ 的奇异值，并且设其奇异值分解为：
    $
      X' = U Sigma V^T
    $
    则主成分变换就是：
    $
      Y = V^T X
    $
= 神经网络的小批量梯度下降法
  在神经网络的训练中，目标往往是 $sum_(i = 1)^N L_i (theta) = sum_(i = 1)^N L(f(x_i, theta), y_i)$，直接使用梯度下降法需要计算全部样本的梯度，往往计算量过大。小批量梯度下降是指，选定样本容量 $n$ 将数据分成 $m$ 组，每轮更新，依次对每组数据计算梯度进行更新。通常称将数据集遍历一次为一个 Epoch。

  实际操作中，我们可以采用多种方式调整超参数，包括：
  - 批量大小 $n$ 的选择。理论上，$n$ 越大方差越小，噪声更小，训练更稳定，可以采用较大的学习率。通常来说，批量大小较小时，可以尝试批量大小和学习率等比增加。实践上，适当小的 $n$ 会导致更快的收敛。
  - 学习率的调整：训练过程中不一定只采用固定的学习率。学习率较大时，可能导致梯度下降不收敛。学习率小时则会收敛太慢。  
  == 优化算法
    #algorithm[动量法][
      如果每次选择的样本比较小，梯度的随机性可能就比较大。为了改善这个问题，可以采用动量法，也即：
      $
        Delta theta_t = rho Delta theta_(t - 1) - eta g_t = - eta sum_(r = 1)^t rho^(t - r) g_r
      $
      其中 $rho$ 是动量因子，它相当于用一段时间内的移动平均替代当前梯度。

      一种改进是 Nesterov 加速，简单来说就是：
      $
        Delta theta_t = rho Delta theta_(t - 1) - eta g_t (theta_(t - 1) + rho Delta theta_(t - 1))
      $
      也就是先做动量修正，之后按修正后的参数计算梯度。
    ]
    #algorithm[Adam][
      Adam 算法是动量法和 RMSProp 的结合，是现代机器学习相当常用的方法。它维护以下几个参数：
      - 梯度的指数加权平均：
        $
          M_t = beta_1 M_(t - 1) + (1 - beta_1) g_t
        $
        以及校正：
        $
          hat(M)_t = M_t / (1 - beta_1^t)
        $
      - 梯度平方的指数加权平均：
        $
          G_t = beta_2 G_(t - 1) + (1 - beta_2) g_t^2
        $
        以及校正：
        $
          hat(G)_t = G_t / (1 - beta_2^t)
        $
      第 $t$ 步时，参数更新如下：
      $
        Delta theta_t = - eta/sqrt(hat(G)_t + epsilon) dot.circle hat(M)_t
      $
      上面的校正是因为，*Adam 算法往往从零值开始更新 $M, G$，如果计算均值，则修正后的参数才与真正值的期望相当。*
    ]
    如果学习过程不稳定，可能会导致梯度爆炸。一种方法是梯度截断，包括：
    - 值截断：将 $g_t$ 的每一维截断至给定的区间 $[a, b]$
    - 按模截断：如果 $norm(g_t) >= b$，则用 $b/norm(g_t) g_t$ 替代，使得模不超过 $b$. 实践发现该方法对超参数 $b$ 并不敏感。
  == 参数初始化\*
    在神经网络中，将参数初始化为零值并不是一个好选项，此时，会导致隐藏层神经元均不能激活。好的初始化当然可以极大地帮助训练，广义上讲，初始化方法有：
    - 预训练初始化 + 精调：直接使用别人训练好的参数作为初始化参数，之后再用小规模数据进行精调。
    - 固定值初始化：根据经验用特殊值初始化一些参数
    - 随机初始化：在没有其他信息的情况下，随机初始化是最常用的方法。通常，我们选定一个零均值的分布，用这个分布随机初始化参数。
      #algorithm[固定方差初始化][
        从一个固定的方差选取的典型分布进行初始化，分布包括：
        - 高斯分布：$N(0, sigma^2)$
        - 均匀分布：$U(-sqrt(3 sigma^2), sqrt(3 sigma^2))$
        对于方差的选择，如果参数范围太小，神经元的输出太小，sigmoid 的非线性不突出；而参数范围太大时，sigmoid 又可能进入饱和区，导致梯度消失。一般，固定方差的方法一般配合逐层归一化使用。
      ]
      #algorithm[基于方差缩放的参数初始化][
        人们研究发现，方差随着神经元链接数量进行缩放是更好的方法。我们希望保证，神经元输入和输出的方差相近。
        - Xavier 初始化：如果忽略神经元的激活函数，设神经元为：
          $
            y = w^T x\
            var y = n var(w_i) var(x_i)
          $
          （假设 $w, x$ 相互独立，零均值），我们希望 $var y$ 与 $var(x_i)$ 接近，因此 $var(w_i)$ 选取 $1/n$ 比较合适，这里 $n$ 就是神经元的输入链接数量。当然，误差反向传播时也要做类似的考虑，因此输出链接的数量也要考虑。通常作为折中，取：
          $
            sigma = 2/(n_1 + n_2)
          $
          其中 $n_1$ 是输入链接数量，$n_2$ 是输出链接数量。

          如果考虑具体的激活函数，可以对激活函数泰勒展开后处理，例如 Sigmoid 情形应取 $16 dot 2/(n_1 + n_2), tanh$ 情形应取 $2/(n_1 + n_2)$.
        - He 初始化：对于采用 Relu 激活函数的神经元，可以直接采用：
          $
            2/(n_1)
          $
          作为方差。

      ]
      #algorithm[正交初始化][
        有时，我们希望梯度传播时具有保范性。做法是，先对权重进行采用，对采用得到的矩阵进行奇异值分解：
        $
          M = U Sigma V^T
        $
        之后，用 $V$ 代替 $M$ 即可。
      ]
  == 数据预处理与逐层归一化\*
    理论上，数据不归一化也可以训练，但实践中，数据归一化可以极大地帮助训练。常用的归一化方法包括：
    - 最大最小值归一化
    - 标准化
    - 白化：消除特征之间的相关性并令特征尽可能同方差，例如 PCA 

    同时，对于隐藏层的输入，我们也可以进行归一化，从而保证更好的尺度不变性（每层数据的分布稳定）和更平滑的优化过程（使得大部分神经元的输入处于不饱和区域，梯度更加稳定）。
    #algorithm[批量归一化][
      设 $x_1, x_2, ..., x_n$ 是一小批数据。每一层之间，仿射变换之后激活函数之前的数据记为 $z$，则每个数据 $x_i$ 都对应 $z_i$。批量归一化的做法是，将 $z_i$ 的每一维归一到标准正态分布。其中，均值和方差常选择最大似然估计。不过，这样归一化的结果可能接近 $0$ 导致 Sigmoid 非线性性不明显，可以再引入一次缩放和平移。在训练完成后，通常可以使用整个数据集上的样本均值和方差作为归一化的参数。
    ]
    #algorithm[层归一化][
      批量归一化是单个神经元，批量数据。而层归一化是单个数据，一个层的所有神经元。也就是，对上面的 $z$ 的所有分量归一化到标准正态分布，之后再做缩放和平移。
    ]
    #algorithm[权重归一化][
      也称为重参数或者再参数技术。对于层之间的线性变换 $W$，将其重参数为 $g_i, v_i$ 其中 $g_i$ 的列的模长，$v_i$ 是单位向量。
    ]
    #algorithm[Dropout][
      在训练过程中，随机将一部分神经元的输出置为 $0$，从而使得网络不依赖于某些神经元的输出。测试时，使用 $p x$（期望）作为实际参数，不再丢弃。
    ]
    #algorithm[inverted dropout][
      类似与 Dropout，不过此时我们以 $p$ 概率做 $1/p$ 拉伸，以 $1 - p$ 概率丢弃，保证期望不变。在模型测试时，为了稳定不再丢弃。
    ]
    其他常用的技巧包括：
    - 数据增强：进行变换，引入噪声等，增强稳定性
    - 标签平滑：多分类问题中，人为为标签引入平滑噪声，防止标签错误时过拟合。
